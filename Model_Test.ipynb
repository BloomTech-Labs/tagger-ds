{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Model_Test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhaWewB3itRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.tokenize.regexp import regexp_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "import pickle\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Embedding, LSTM, GRU\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dropout, SpatialDropout1D, Input, concatenate\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UD6iZMIALJ8H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "0e3ccf63-f1a3-46c1-e9f7-391ff31a155b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmRNZCQZitRo",
        "colab_type": "code",
        "outputId": "45574e6d-84ab-4adc-91a8-89bef18660cd",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1bcef72b-96f1-41c8-8680-8366b7edbab6\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-1bcef72b-96f1-41c8-8680-8366b7edbab6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving update_twelve_three.csv to update_twelve_three.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gszSwWys_0Hy",
        "colab_type": "code",
        "outputId": "db60542e-e442-47ab-de9b-be1ec17eb5b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/update_twelve_three.csv')\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>From</th>\n",
              "      <th>Message</th>\n",
              "      <th>Subject</th>\n",
              "      <th>Tags</th>\n",
              "      <th>UID</th>\n",
              "      <th>text</th>\n",
              "      <th>tag_list</th>\n",
              "      <th>first_tag</th>\n",
              "      <th>sender_name</th>\n",
              "      <th>sender_email</th>\n",
              "      <th>domain_name</th>\n",
              "      <th>isNoReply</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;grangepayments@westernunionspeedpay.com&gt;</td>\n",
              "      <td>Dear AVRAHAM JACOBSOHN,  This is to confirm th...</td>\n",
              "      <td>Grange Payment Confirmation</td>\n",
              "      <td>Finance</td>\n",
              "      <td>31780</td>\n",
              "      <td>&lt;grangepayments@westernunionspeedpay.com&gt; Gran...</td>\n",
              "      <td>['Finance']</td>\n",
              "      <td>Finance</td>\n",
              "      <td>NaN</td>\n",
              "      <td>grangepayments@westernunionspeedpay.com</td>\n",
              "      <td>westernunionspeedpay</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Chase &lt;no.reply.alerts@chase.com&gt;</td>\n",
              "      <td>This is an Alert to help manage your account ...</td>\n",
              "      <td>Your Debit Card Transaction</td>\n",
              "      <td>Finance</td>\n",
              "      <td>31779</td>\n",
              "      <td>Chase &lt;no.reply.alerts@chase.com&gt; Your Debit C...</td>\n",
              "      <td>['Finance']</td>\n",
              "      <td>Finance</td>\n",
              "      <td>Chase</td>\n",
              "      <td>no.reply.alerts@chase.com</td>\n",
              "      <td>chase</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Amazon Web Services &lt;no-reply-aws@amazon.com&gt;</td>\n",
              "      <td>Please let us know if we helped resolve your i...</td>\n",
              "      <td>Resolved 6559329691: Limit Increase: SageMaker</td>\n",
              "      <td>Productivity</td>\n",
              "      <td>31738</td>\n",
              "      <td>Amazon Web Services &lt;no-reply-aws@amazon.com&gt; ...</td>\n",
              "      <td>['Productivity']</td>\n",
              "      <td>Productivity</td>\n",
              "      <td>Amazon Web Services</td>\n",
              "      <td>no-reply-aws@amazon.com</td>\n",
              "      <td>amazon</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lambda Labs &lt;noreply@github.com&gt;</td>\n",
              "      <td>Youve been added to the Labs 18 - Tagger team ...</td>\n",
              "      <td>Bernie Durfee added you to the Lambda Labs tea...</td>\n",
              "      <td>Productivity</td>\n",
              "      <td>31693</td>\n",
              "      <td>Lambda Labs &lt;noreply@github.com&gt; Bernie Durfee...</td>\n",
              "      <td>['Productivity']</td>\n",
              "      <td>Productivity</td>\n",
              "      <td>Lambda Labs</td>\n",
              "      <td>noreply@github.com</td>\n",
              "      <td>github</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Amazon Web Services &lt;no-reply-aws@amazon.com&gt;</td>\n",
              "      <td>Hello,  We haven't heard back from you regard...</td>\n",
              "      <td>Attention required on case 6559329691: Limit I...</td>\n",
              "      <td>Productivity</td>\n",
              "      <td>31684</td>\n",
              "      <td>Amazon Web Services &lt;no-reply-aws@amazon.com&gt; ...</td>\n",
              "      <td>['Productivity']</td>\n",
              "      <td>Productivity</td>\n",
              "      <td>Amazon Web Services</td>\n",
              "      <td>no-reply-aws@amazon.com</td>\n",
              "      <td>amazon</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            From  ... isNoReply\n",
              "0      <grangepayments@westernunionspeedpay.com>  ...     False\n",
              "1              Chase <no.reply.alerts@chase.com>  ...      True\n",
              "2  Amazon Web Services <no-reply-aws@amazon.com>  ...      True\n",
              "3               Lambda Labs <noreply@github.com>  ...      True\n",
              "4  Amazon Web Services <no-reply-aws@amazon.com>  ...      True\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm1usu18VrKN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "da4abaa4-95d2-4a07-aa2d-ae0a195540e1"
      },
      "source": [
        "df['Message'][0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dear AVRAHAM JACOBSOHN,  This is to confirm that a card payment for 142.48 was made to your Grange account ending in 1173 using the card ending in 2308.  Confirmation Number: 6786423  Scheduled Payment Date: 11/08/2019  Payment Amount: 142.48  Last 4 of Card: 2308  Please contact Grange Insurance at 1-800-425-1100 if you have any questions.  Sincerely,  Grange Insurance  Please note:  This email message was sent from a notification-only address that cannot accept incoming email.  Please do not reply to this message.  '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxhryVWcdwzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change the name of the column with From + Subject + Message\n",
        "\n",
        "df.rename(columns={'text':'Combined_Text'}, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEhxUZs4GxTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to clean the text prior to tokenizing\n",
        "\n",
        "def clean_text(text):\n",
        "    # Perform a few cleaning steps to remove non-alphabetic characters\n",
        "    \n",
        "    text = text.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
        "\n",
        "    text = text.strip(\" \")\n",
        "    \n",
        "    punc_list = '!@#$%^&*()+?-_=:.<>[]{}/\\~\",©' + '1234567890'\n",
        "    t = str.maketrans(dict.fromkeys(punc_list, \" \"))\n",
        "    text = text.translate(t)\n",
        "    \n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwHdyjfWM1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clean the From Message and Subject before separating to different models\n",
        "\n",
        "df['Clean_Message'] = df['Message'].apply(clean_text)\n",
        "\n",
        "df['Clean_From'] = df['From'].apply(clean_text)\n",
        "\n",
        "df['Clean_Subject'] = df['Subject'].apply(clean_text)\n",
        "\n",
        "df['Combined_Text'] = df['Combined_Text'].apply(clean_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS_B87XnWOk0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "outputId": "ac38643d-3b0d-4caa-f8b8-7ffc9504d73a"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>From</th>\n",
              "      <th>Message</th>\n",
              "      <th>Subject</th>\n",
              "      <th>Tags</th>\n",
              "      <th>UID</th>\n",
              "      <th>Combined_Text</th>\n",
              "      <th>tag_list</th>\n",
              "      <th>first_tag</th>\n",
              "      <th>sender_name</th>\n",
              "      <th>sender_email</th>\n",
              "      <th>domain_name</th>\n",
              "      <th>isNoReply</th>\n",
              "      <th>Clean_Message</th>\n",
              "      <th>Clean_From</th>\n",
              "      <th>Clean_Subject</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;grangepayments@westernunionspeedpay.com&gt;</td>\n",
              "      <td>Dear AVRAHAM JACOBSOHN,  This is to confirm th...</td>\n",
              "      <td>Grange Payment Confirmation</td>\n",
              "      <td>Finance</td>\n",
              "      <td>31780</td>\n",
              "      <td>grangepayments westernunionspeedpay com  Gran...</td>\n",
              "      <td>['Finance']</td>\n",
              "      <td>Finance</td>\n",
              "      <td>NaN</td>\n",
              "      <td>grangepayments@westernunionspeedpay.com</td>\n",
              "      <td>westernunionspeedpay</td>\n",
              "      <td>False</td>\n",
              "      <td>Dear AVRAHAM JACOBSOHN   This is to confirm th...</td>\n",
              "      <td>grangepayments westernunionspeedpay com</td>\n",
              "      <td>Grange Payment Confirmation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Chase &lt;no.reply.alerts@chase.com&gt;</td>\n",
              "      <td>This is an Alert to help manage your account ...</td>\n",
              "      <td>Your Debit Card Transaction</td>\n",
              "      <td>Finance</td>\n",
              "      <td>31779</td>\n",
              "      <td>Chase  no reply alerts chase com  Your Debit C...</td>\n",
              "      <td>['Finance']</td>\n",
              "      <td>Finance</td>\n",
              "      <td>Chase</td>\n",
              "      <td>no.reply.alerts@chase.com</td>\n",
              "      <td>chase</td>\n",
              "      <td>True</td>\n",
              "      <td>This is an Alert to help manage your account e...</td>\n",
              "      <td>Chase  no reply alerts chase com</td>\n",
              "      <td>Your Debit Card Transaction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Amazon Web Services &lt;no-reply-aws@amazon.com&gt;</td>\n",
              "      <td>Please let us know if we helped resolve your i...</td>\n",
              "      <td>Resolved 6559329691: Limit Increase: SageMaker</td>\n",
              "      <td>Productivity</td>\n",
              "      <td>31738</td>\n",
              "      <td>Amazon Web Services  no reply aws amazon com  ...</td>\n",
              "      <td>['Productivity']</td>\n",
              "      <td>Productivity</td>\n",
              "      <td>Amazon Web Services</td>\n",
              "      <td>no-reply-aws@amazon.com</td>\n",
              "      <td>amazon</td>\n",
              "      <td>True</td>\n",
              "      <td>Please let us know if we helped resolve your i...</td>\n",
              "      <td>Amazon Web Services  no reply aws amazon com</td>\n",
              "      <td>Resolved             Limit Increase  SageMaker</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lambda Labs &lt;noreply@github.com&gt;</td>\n",
              "      <td>Youve been added to the Labs 18 - Tagger team ...</td>\n",
              "      <td>Bernie Durfee added you to the Lambda Labs tea...</td>\n",
              "      <td>Productivity</td>\n",
              "      <td>31693</td>\n",
              "      <td>Lambda Labs  noreply github com  Bernie Durfee...</td>\n",
              "      <td>['Productivity']</td>\n",
              "      <td>Productivity</td>\n",
              "      <td>Lambda Labs</td>\n",
              "      <td>noreply@github.com</td>\n",
              "      <td>github</td>\n",
              "      <td>True</td>\n",
              "      <td>Youve been added to the Labs      Tagger team ...</td>\n",
              "      <td>Lambda Labs  noreply github com</td>\n",
              "      <td>Bernie Durfee added you to the Lambda Labs tea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Amazon Web Services &lt;no-reply-aws@amazon.com&gt;</td>\n",
              "      <td>Hello,  We haven't heard back from you regard...</td>\n",
              "      <td>Attention required on case 6559329691: Limit I...</td>\n",
              "      <td>Productivity</td>\n",
              "      <td>31684</td>\n",
              "      <td>Amazon Web Services  no reply aws amazon com  ...</td>\n",
              "      <td>['Productivity']</td>\n",
              "      <td>Productivity</td>\n",
              "      <td>Amazon Web Services</td>\n",
              "      <td>no-reply-aws@amazon.com</td>\n",
              "      <td>amazon</td>\n",
              "      <td>True</td>\n",
              "      <td>Hello   We haven't heard back from you regardi...</td>\n",
              "      <td>Amazon Web Services  no reply aws amazon com</td>\n",
              "      <td>Attention required on case             Limit I...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            From  ...                                      Clean_Subject\n",
              "0      <grangepayments@westernunionspeedpay.com>  ...                        Grange Payment Confirmation\n",
              "1              Chase <no.reply.alerts@chase.com>  ...                        Your Debit Card Transaction\n",
              "2  Amazon Web Services <no-reply-aws@amazon.com>  ...     Resolved             Limit Increase  SageMaker\n",
              "3               Lambda Labs <noreply@github.com>  ...  Bernie Durfee added you to the Lambda Labs tea...\n",
              "4  Amazon Web Services <no-reply-aws@amazon.com>  ...  Attention required on case             Limit I...\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fNuPHE1SdLi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "outputId": "2d681018-0d84-46e4-c74b-b1b1dd8c526b"
      },
      "source": [
        "df['tag_list'].value_counts()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Finance']                      5604\n",
              "['Entertainment']                1505\n",
              "['Shopping']                     1065\n",
              "['Personal', 'Other']             685\n",
              "['Productivity']                  514\n",
              "['Other']                         514\n",
              "['Personal', 'Productivity']      382\n",
              "['Social']                        146\n",
              "['Productivity', 'Events']        130\n",
              "['Entertainment', 'Finance']      102\n",
              "['Events']                         95\n",
              "['Personal', 'Shopping']           95\n",
              "['Personal', 'Events']             95\n",
              "['Travel']                         92\n",
              "['Personal', 'Finance']            69\n",
              "['Personal', 'Travel']             25\n",
              "['Personal', 'Entertainment']      19\n",
              "['Shopping', 'Finance']            13\n",
              "['Entertainment', 'Shopping']      10\n",
              "['Events', 'Productivity']          8\n",
              "['Travel', 'Finance']               5\n",
              "['Productivity', 'Finance']         4\n",
              "['Personal', 'Social']              4\n",
              "['Shopping', 'Entertainment']       4\n",
              "['Social', 'Productivity']          4\n",
              "['Shopping', 'Productivity']        2\n",
              "['Finance', 'Travel']               2\n",
              "['Productivity', 'Shopping']        1\n",
              "['Events', 'Entertainment']         1\n",
              "['Finance', 'Events']               1\n",
              "['Finance', 'Productivity']         1\n",
              "['Finance', 'Shopping']             1\n",
              "Name: tag_list, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph6GGRbdSyzm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "outputId": "13939edc-b2f3-4f2e-db23-d9061a09d496"
      },
      "source": [
        "df['Tags'].value_counts()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Finance                    5604\n",
              "Entertainment              1505\n",
              "Shopping                   1065\n",
              "Personal, Other             685\n",
              "Productivity                514\n",
              "Other                       514\n",
              "Personal, Productivity      382\n",
              "Social                      146\n",
              "Productivity, Events        130\n",
              "Entertainment, Finance      102\n",
              "Personal, Shopping           95\n",
              "Personal, Events             95\n",
              "Events                       95\n",
              "Travel                       92\n",
              "Personal, Finance            69\n",
              "Personal, Travel             25\n",
              "Personal, Entertainment      19\n",
              "Shopping, Finance            13\n",
              "Entertainment, Shopping      10\n",
              "Events, Productivity          8\n",
              "Travel, Finance               5\n",
              "Productivity, Finance         4\n",
              "Social, Productivity          4\n",
              "Shopping, Entertainment       4\n",
              "Personal, Social              4\n",
              "Finance, Travel               2\n",
              "Shopping, Productivity        2\n",
              "Finance, Shopping             1\n",
              "Events, Entertainment         1\n",
              "Finance, Events               1\n",
              "Finance, Productivity         1\n",
              "Productivity, Shopping        1\n",
              "Name: Tags, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj2T37nOSmu_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "8b48f09d-f4b6-4885-977d-04fbba43e133"
      },
      "source": [
        "# Creating Personal Column\n",
        "\n",
        "df['Personal'] = df['Tags'].str.contains('Personal')\n",
        "df['Personal'].value_counts()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    9824\n",
              "True     1374\n",
              "Name: Personal, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaBzqwYYG0jA",
        "colab_type": "code",
        "outputId": "04cee3d0-a0f8-4d15-ef3a-f7ea41139a0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Applying length of CLEAN messages as feature\n",
        "\n",
        "df['Clean_Text_Length'] = df['Clean_Message'].apply(len)\n",
        "print(df['Clean_Text_Length'].min(), df['Clean_Text_Length'].max())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 3732402\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp5Bj6JnG2Se",
        "colab_type": "code",
        "outputId": "a7f4e25a-03e6-4993-d937-5ee411586cd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Most lengths are below 5000 even with a max of 370k length\n",
        "\n",
        "clean_text_length = df['Clean_Text_Length'] < 5000\n",
        "clean_text_length.value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True     10544\n",
              "False      654\n",
              "Name: Clean_Text_Length, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEAN2_5PG39c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# def regnltk_tokenize(text):\n",
        "#     text = clean_text(text)\n",
        "#     words = regexp_tokenize(text, pattern = '\\s+', gaps = True)\n",
        "#     return [lemmatizer.lemmatize(word.lower()) for word in words if (len(word) >= 3)] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpfetY0tZNiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove too small and too large texts from the messages before tokenizing\n",
        "\n",
        "message_values = df['Combined_Text'].values\n",
        "\n",
        "tokens = []\n",
        "\n",
        "for i in range(len(message_values)):\n",
        "    value = message_values[i]\n",
        "    value = value.split(\" \")\n",
        "    value = [x for x in value if len(x) > 3 and len(x) < 20]\n",
        "    value = \" \".join(value)\n",
        "    tokens.append(value)\n",
        "\n",
        "tokens\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ERBtrKuIZHw",
        "colab_type": "text"
      },
      "source": [
        "## Start of Keras Work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaH-6EDDG65r",
        "colab_type": "code",
        "outputId": "f1753a97-70c0-4e42-8e03-3a489975ff70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Starting tokenizing from keras preprocessing\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True, split=' ')\n",
        "tokenizer.fit_on_texts(tokens)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "# saving\n",
        "with open('final_tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "files.download('final_tokenizer.pickle')"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 407235 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crClksY_JpjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7ImvnQAPopT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b1171f85-33fd-49c6-d8b1-dc4ba1f1fb5e"
      },
      "source": [
        "# Split the data into train/test prior to prepping for each model\n",
        "\n",
        "X = df.drop(columns=['tag_list', 'first_tag'])\n",
        "\n",
        "Y = df['first_tag']\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.10, random_state = 42)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10078, 15) (10078,)\n",
            "(1120, 15) (1120,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Inv2Xxd5e9yH",
        "colab_type": "text"
      },
      "source": [
        "#### Format all of the inputs for each Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkUoeZlRPjCi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5537b812-44b2-44f9-a3ea-a8d203ce3f62"
      },
      "source": [
        "# Format the inputs for Model 1 of predicting tag from message body\n",
        "\n",
        "Message_X_train = tokenizer.texts_to_sequences(X_train['Clean_Message'].values)\n",
        "Message_X_train = pad_sequences(Message_X_train, maxlen=5000)\n",
        "print('Shape of data tensor:', Message_X_train.shape)\n",
        "\n",
        "Message_X_test = tokenizer.texts_to_sequences(X_test['Clean_Message'].values)\n",
        "Message_X_test = pad_sequences(Message_X_test, maxlen=5000)\n",
        "print('Shape of data tensor:', Message_X_test.shape)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (10078, 5000)\n",
            "Shape of data tensor: (1120, 5000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkHlIFgZT_w3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1324624c-505c-4bcb-ea10-e4f326104800"
      },
      "source": [
        "# Format the inputs for Model 2 of predicting tag from message subject\n",
        "\n",
        "# First need to get length of subject messages\n",
        "\n",
        "clean_subject_length = df['Clean_Subject'].apply(len)\n",
        "(clean_subject_length < 150).value_counts()\n",
        "\n",
        "# Most are below 150 in length, will use this to pad\n",
        "\n",
        "Subject_X_train = tokenizer.texts_to_sequences(X_train['Clean_Subject'].values)\n",
        "Subject_X_train = pad_sequences(Subject_X_train, maxlen=150)\n",
        "print('Shape of data tensor:', Subject_X_train.shape)\n",
        "\n",
        "Subject_X_test = tokenizer.texts_to_sequences(X_test['Clean_Subject'].values)\n",
        "Subject_X_test = pad_sequences(Subject_X_test, maxlen=150)\n",
        "print('Shape of data tensor:', Subject_X_test.shape)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (10078, 150)\n",
            "Shape of data tensor: (1120, 150)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dpyf6fJYX9Kz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "8b7427b2-fe29-4210-bb4b-1c0a0343a4f3"
      },
      "source": [
        "# Format the inputs for Model 3 of predicting tag from message sender\n",
        "\n",
        "# First need to get length of From messages sender\n",
        "\n",
        "clean_from_length = df['Clean_From'].apply(len)\n",
        "mean = clean_from_length.mean()\n",
        "print(mean)\n",
        "(clean_from_length < 100).value_counts()\n",
        "\n",
        "# Most are below 100 in length, will use this to pad\n",
        "\n",
        "From_X_train = tokenizer.texts_to_sequences(X_train['Clean_From'].values)\n",
        "From_X_train = pad_sequences(From_X_train, maxlen=100)\n",
        "print('Shape of data tensor:', From_X_train.shape)\n",
        "\n",
        "From_X_test = tokenizer.texts_to_sequences(X_test['Clean_From'].values)\n",
        "From_X_test = pad_sequences(From_X_test, maxlen=100)\n",
        "print('Shape of data tensor:', From_X_test.shape)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39.714770494731205\n",
            "Shape of data tensor: (10078, 100)\n",
            "Shape of data tensor: (1120, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlNViWFYHHLA",
        "colab_type": "code",
        "outputId": "de9b62f6-deac-4350-9107-a7f0990fe792",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Format the Y inputs with encoding\n",
        "\n",
        "Encoded_Y_train = pd.get_dummies(Y_train).values\n",
        "print('Shape of label tensor:', Encoded_Y_train.shape)\n",
        "\n",
        "Encoded_Y_test = pd.get_dummies(Y_test).values\n",
        "print('Shape of label tensor:', Encoded_Y_test.shape)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of label tensor: (10078, 8)\n",
            "Shape of label tensor: (1120, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBpVjSd2PI0K",
        "colab_type": "code",
        "outputId": "a797ac3d-9a51-4d88-b2c4-c1c41a84055c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Use these columns for the labels when decoding the neural net\n",
        "\n",
        "print(pd.get_dummies(df['first_tag']).columns)\n",
        "\n",
        "labels = ['Entertainment', 'Events', 'Finance', 'Other', 'Productivity',\n",
        "       'Shopping', 'Social', 'Travel']"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Entertainment', 'Events', 'Finance', 'Other', 'Productivity',\n",
            "       'Shopping', 'Social', 'Travel'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVfjt_nPE2qq",
        "colab_type": "text"
      },
      "source": [
        "#### Setting up the Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mm_tf0BvuDF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LSTM function\n",
        "\n",
        "def create_lstm(X):\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(50000, 100, input_length=X.shape[1]))\n",
        "    model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
        "    model.add(GRU(50, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
        "    model.add(GRU(50, dropout=0.2, recurrent_dropout=0.2))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWsOg6J35KQN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model for message, subject, and sender\n",
        "\n",
        "message_model = create_lstm(Message_X_train)\n",
        "subject_model = create_lstm(Subject_X_train)\n",
        "from_model = create_lstm(From_X_train)\n",
        "\n",
        "# Combine them all for the activation input\n",
        "\n",
        "combined_input = concatenate([message_model.output, subject_model.output, from_model.output])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M93mOgWzDzUr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        },
        "outputId": "8c8e8244-dc54-48e8-88f9-8e7676d5a6a5"
      },
      "source": [
        "# End activation of model\n",
        "\n",
        "x = Dense(8, activation='softmax')(combined_input)\n",
        "\n",
        "model = Model(inputs=[message_model.input, subject_model.input, from_model.input], outputs=x)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "embedding_16_input (InputLayer) (None, 5000)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_17_input (InputLayer) (None, 150)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_18_input (InputLayer) (None, 100)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_16 (Embedding)        (None, 5000, 100)    5000000     embedding_16_input[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "embedding_17 (Embedding)        (None, 150, 100)     5000000     embedding_17_input[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "embedding_18 (Embedding)        (None, 100, 100)     5000000     embedding_18_input[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "lstm_15 (LSTM)                  (None, 5000, 100)    80400       embedding_16[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm_16 (LSTM)                  (None, 150, 100)     80400       embedding_17[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm_17 (LSTM)                  (None, 100, 100)     80400       embedding_18[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "gru_29 (GRU)                    (None, 5000, 50)     22650       lstm_15[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gru_31 (GRU)                    (None, 150, 50)      22650       lstm_16[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gru_33 (GRU)                    (None, 100, 50)      22650       lstm_17[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gru_30 (GRU)                    (None, 50)           15150       gru_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "gru_32 (GRU)                    (None, 50)           15150       gru_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "gru_34 (GRU)                    (None, 50)           15150       gru_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 150)          0           gru_30[0][0]                     \n",
            "                                                                 gru_32[0][0]                     \n",
            "                                                                 gru_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 8)            1208        concatenate_3[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 15,355,808\n",
            "Trainable params: 15,355,808\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu2MMQDCE97p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "7099cc0e-9479-48c0-c15e-5ad3c76ae26d"
      },
      "source": [
        "# train the model\n",
        "print(\"[INFO] training model...\")\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "batch_size=64\n",
        "\n",
        "model.fit(\n",
        "\t[Message_X_train, Subject_X_train, From_X_train], Encoded_Y_train,\n",
        "\tvalidation_data=([Message_X_test, Subject_X_test, From_X_test], Encoded_Y_test),\n",
        "\tepochs=epochs, batch_size=batch_size,\n",
        "  callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)]\n",
        "  )\n",
        " \n",
        "# make predictions on the testing data\n",
        "print(\"[INFO] predicting house prices...\")\n",
        "preds = model.predict([Message_X_test, Subject_X_test, From_X_test])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] training model...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 10078 samples, validate on 1120 samples\n",
            "Epoch 1/3\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "  256/10078 [..............................] - ETA: 1:04:38 - loss: 2.0313 - acc: 0.3945"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI0RbAIZHKTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Side notes to look back into, especially attention layer\n",
        "\n",
        "# GRU layers can be added as well as LSTM, GRU > LSTM\n",
        "\n",
        "# attention models or attention transformed models\n",
        "\n",
        "# clustering in different forms for unsupervised training and then try to label them\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrX30PQpHLh2",
        "colab_type": "code",
        "outputId": "e8d332d3-0454-4e7c-b486-0d2ccf399178",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "epochs = 1\n",
        "batch_size = 64\n",
        "\n",
        "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 9070 samples, validate on 1008 samples\n",
            "Epoch 1/1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "9070/9070 [==============================] - 1691s 186ms/step - loss: 0.8158 - acc: 0.7323 - val_loss: 0.3705 - val_acc: 0.8819\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXxmsFaoCm6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving model and weights\n",
        "\n",
        "\n",
        "#---------------------------\n",
        "## Change name each time ##\n",
        "#---------------------------\n",
        "\n",
        "from google.colab import files\n",
        "from keras.models import model_from_json\n",
        "model_json = model.to_json()\n",
        "with open(\"test_model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights(\"test_weights.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXGfCeNCMKcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "996HRv8e-qfo",
        "colab_type": "code",
        "outputId": "21fee373-d44e-41cc-ab71-b08810874c8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "first = df['Clean_Message'][0]\n",
        "len(first)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "591"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNZV1AJ5MQwi",
        "colab_type": "code",
        "outputId": "ea35bf24-08ff-4a43-a4e0-0614d993bd2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "# load json and create model\n",
        "json_file = open('test_model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"test_weights.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        "\n",
        "def tag_email(text, model):\n",
        "    '''\n",
        "    Clean the text with the clean_text function\n",
        "\n",
        "    Tokenize the text and pad it\n",
        "\n",
        "    Use the loaded LSTM model softmax activation to predict the probability of each label\n",
        "    for the email message being tested\n",
        "\n",
        "    Return the highest argument as the predicted label\n",
        "    '''\n",
        "\n",
        "    text = clean_text(text)\n",
        "    print('Text clean')\n",
        "    print(text)\n",
        "    print(len(text))\n",
        "    seq = tokenizer.texts_to_sequences([text])\n",
        "    print('Text sequenced')\n",
        "    print(len(seq))\n",
        "    padded = pad_sequences(seq, maxlen=5000)\n",
        "    print('Text padded')\n",
        "    print(len(padded))\n",
        "    labels = ['Entertainment', 'Events', 'Finance', 'Other', 'Productivity', 'Shopping', 'Social', 'Travel']\n",
        "\n",
        "    pred = model.predict(padded)\n",
        "    print('Label predicted')\n",
        "    return labels[np.argmax(pred)]\n",
        "result = tag_email(first, loaded_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n",
            "Text clean\n",
            "grangepayments westernunionspeedpay com  Grange Payment Confirmation Dear AVRAHAM JACOBSOHN   This is to confirm that a card payment for        was made to your Grange account ending in      using the card ending in        Confirmation Number           Scheduled Payment Date              Payment Amount          Last   of Card        Please contact Grange Insurance at                if you have any questions   Sincerely   Grange Insurance  Please note   This email message was sent from a notification only address that cannot accept incoming email   Please do not reply to this message\n",
            "589\n",
            "Text sequenced\n",
            "1\n",
            "Text padded\n",
            "1\n",
            "Label predicted\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hSlOe38Iaxg",
        "colab_type": "code",
        "outputId": "3b8f22eb-5b8a-4949-ffbf-4f44df83648d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "result.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QNTbBnkKVow",
        "colab_type": "code",
        "outputId": "6ab1b6ea-87c1-4c5d-d736-77a70219674a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Finance'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQBOKLxiHg8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accr = model.evaluate(X_test,Y_test)\n",
        "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uEhz3oaYi6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.title('Loss')\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "486-J91eYnjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.title('Accuracy')\n",
        "plt.plot(history.history['acc'], label='train')\n",
        "plt.plot(history.history['val_acc'], label='test')\n",
        "plt.legend()\n",
        "plt.show();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7Nu6Ir1YrHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}