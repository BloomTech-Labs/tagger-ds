{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_records': 400000,\n",
       " 'file_size': 69182535,\n",
       " 'base_dataset': 'Wikipedia 2014 + Gigaword 5 (6B tokens, uncased)',\n",
       " 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-wiki-gigaword-50/__init__.py',\n",
       " 'license': 'http://opendatacommons.org/licenses/pddl/',\n",
       " 'parameters': {'dimension': 50},\n",
       " 'description': 'Pre-trained vectors based on Wikipedia 2014 + Gigaword, 5.6B tokens, 400K vocab, uncased (https://nlp.stanford.edu/projects/glove/).',\n",
       " 'preprocessing': 'Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-wiki-gigaword-50.txt`.',\n",
       " 'read_more': ['https://nlp.stanford.edu/projects/glove/',\n",
       "  'https://nlp.stanford.edu/pubs/glove.pdf'],\n",
       " 'checksum': 'c289bc5d7f2f02c6dc9f2f9b67641813',\n",
       " 'file_name': 'glove-wiki-gigaword-50.gz',\n",
       " 'parts': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.info('glove-wiki-gigaword-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cash', 0.8989869356155396),\n",
       " ('paying', 0.8788655996322632),\n",
       " ('funds', 0.8768925070762634),\n",
       " ('pay', 0.8716533184051514),\n",
       " ('raise', 0.8444491028785706),\n",
       " ('paid', 0.8426087498664856),\n",
       " ('billions', 0.821241021156311),\n",
       " ('millions', 0.8198676109313965),\n",
       " ('get', 0.8128967881202698),\n",
       " ('fund', 0.8083053827285767)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model = api.load(\"glove-wiki-gigaword-50\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vacations', 0.8684797286987305),\n",
       " ('honeymoon', 0.8410800695419312),\n",
       " ('trip', 0.7668671011924744),\n",
       " ('trips', 0.7665766477584839),\n",
       " ('holiday', 0.7363888025283813),\n",
       " ('destination', 0.73128342628479),\n",
       " ('holidays', 0.7234708070755005),\n",
       " ('travel', 0.718468189239502),\n",
       " ('weekends', 0.7097956538200378),\n",
       " ('getaway', 0.7050626277923584)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.most_similar('vacation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('toys', 0.8808256387710571),\n",
       " ('doll', 0.7762622237205505),\n",
       " ('dolls', 0.7529333233833313),\n",
       " ('shoe', 0.7435762882232666),\n",
       " ('candy', 0.7196512818336487),\n",
       " ('accessories', 0.7080535292625427),\n",
       " ('shop', 0.6966851949691772),\n",
       " ('barbie', 0.6843433380126953),\n",
       " ('makers', 0.6824744939804077),\n",
       " ('sells', 0.6747361421585083)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.most_similar('toy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2v_model.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'real estate home owner'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [word for word in simple_preprocess(s) if word not in STOPWORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('real', 'estate')\n",
      "('estate', 'home')\n",
      "('home', 'owner')\n"
     ]
    }
   ],
   "source": [
    "n_grams = ngrams(s.split(), 2)\n",
    "for gram in n_grams:\n",
    "    print(gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('income-producing', 0.7051293849945068), ('speculator', 0.6807714700698853), ('developer', 0.676442563533783), ('securitization', 0.6677945852279663), ('small-business', 0.6635185480117798), ('coldwell', 0.6493443250656128), ('import-export', 0.6408600807189941), ('linense', 0.6333641409873962), ('bbk', 0.6135435104370117), ('biocontrol', 0.6133579015731812)]\n",
      "[('inc.com', 0.7484769225120544), ('gph03', 0.7419995069503784), ('bkb', 0.7410009503364563), ('hbh', 0.7389847040176392), ('ak07', 0.7236950993537903), ('usa.com', 0.7206704616546631), ('bpt', 0.7087136507034302), ('dkt', 0.7028523683547974), ('jnm', 0.7023768424987793), ('online.org', 0.6967605948448181)]\n",
      "[('renters', 0.852698564529419), ('homeowners', 0.7744032144546509), ('tenant', 0.7056605815887451), ('tenants', 0.6948038339614868), ('landlord', 0.6896642446517944), ('delinquent', 0.6835854053497314), ('renter', 0.6790680289268494), ('landlords', 0.677708625793457), ('retirees', 0.6738525629043579), ('unemployed', 0.6645784378051758)]\n"
     ]
    }
   ],
   "source": [
    "n_grams = ngrams(s.split(), 2)\n",
    "for gram in n_grams:\n",
    "    hyphenated = '-'.join(gram)\n",
    "    if hyphenated in w2v_model.vocab.keys():\n",
    "        print(w2v_model.most_similar(hyphenated))\n",
    "    \n",
    "    compounded = ''.join(gram)\n",
    "    if compounded in w2v_model.vocab.keys():\n",
    "        print(w2v_model.most_similar(compounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toy\n",
      "doll\n",
      "doll\n",
      "shoe\n",
      "candy\n",
      "accessory\n",
      "shop\n",
      "barbie\n",
      "maker\n",
      "sell\n"
     ]
    }
   ],
   "source": [
    "matches = w2v_model.most_similar('toy')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for match in matches:\n",
    "    print(lemmatizer.lemmatize(match[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['toy', 'doll', 'shoe']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = 'toy'\n",
    "matches = w2v_model.most_similar(search)\n",
    "results = [search]\n",
    "for match in matches:\n",
    "        if lemmatizer.lemmatize(match[0]) not in results and len(results) < 3:\n",
    "            results.append(match[0])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GOOGLE MODEL\n",
    "google_model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "google_model.most_similar('toys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python tagger",
   "language": "python",
   "name": "tagger"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
