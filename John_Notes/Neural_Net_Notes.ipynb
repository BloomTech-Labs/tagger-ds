{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a wide and deep neural network, JC recommended creating a class that combines many aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting category_encoders\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/52/c54191ad3782de633ea3d6ee3bb2837bda0cf3bc97644bb6375cf14150a0/category_encoders-2.1.0-py2.py3-none-any.whl (100kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 28.7MB/s a 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from category_encoders) (1.14.3)\n",
      "Requirement already satisfied: pandas>=0.21.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from category_encoders) (0.24.2)\n",
      "Requirement already satisfied: patsy>=0.4.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from category_encoders) (0.5.0)\n",
      "Requirement already satisfied: statsmodels>=0.6.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from category_encoders) (0.9.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from category_encoders) (0.20.3)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from category_encoders) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from pandas>=0.21.1->category_encoders) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2011k in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from pandas>=0.21.1->category_encoders) (2018.4)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from patsy>=0.4.1->category_encoders) (1.11.0)\n",
      "Installing collected packages: category-encoders\n",
      "Successfully installed category-encoders-2.1.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting spacy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/13/80ad28ef7a16e2a86d16d73e28588be5f1085afd3e85e4b9b912bd700e8a/spacy-2.2.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.4MB 5.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting plac<1.2.0,>=0.9.6 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/86/85/40b8f66c2dd8f4fd9f09d59b22720cffecf1331e788b8a0cab5bafb353d1/plac-1.1.3-py2.py3-none-any.whl\n",
      "Collecting numpy>=1.15.0 (from spacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/ab/43e678759326f728de861edbef34b8e2ad1b1490505f20e0d1f0716c3bf4/numpy-1.17.4-cp36-cp36m-manylinux1_x86_64.whl (20.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 20.0MB 2.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/a6/e6/63f160a4fdf0e875d16b28f972083606d8d54f56cd30cb8929f9a1ee700e/murmurhash-1.0.2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting thinc<7.4.0,>=7.3.0 (from spacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/59/6bb553bc9a5f072d3cd479fc939fea0f6f682892f1f5cff98de5c9b615bb/thinc-7.3.1-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.2MB 23.6MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from spacy) (39.1.0)\n",
      "Collecting catalogue<1.1.0,>=0.0.7 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/4f/d5/46ff975f0d7d055cf95557b944fd5d29d9dfb37a4341038e070f212b24fe/catalogue-0.0.8-py2.py3-none-any.whl\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/6b/e07fad36913879757c90ba03d6fb7f406f7279e11dcefc105ee562de63ea/preshed-3.0.2-cp36-cp36m-manylinux1_x86_64.whl (119kB)\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 41.0MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting blis<0.5.0,>=0.4.0 (from spacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/19/f95c75562d18eb27219df3a3590b911e78d131b68466ad79fdf5847eaac4/blis-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.7MB 17.9MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/b5/3e1714ebda8fd7c5859f9b216e381adc0a38b962f071568fd00d67e1b1ca/cymem-2.0.3-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting wasabi<1.1.0,>=0.4.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/ff/ef/e8266e158ed32bf5f723fac862b6518833d0b53ca183165a8718f212c0d5/wasabi-0.4.2-py3-none-any.whl\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from spacy) (2.20.0)\n",
      "Collecting srsly<1.1.0,>=0.1.0 (from spacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/fb/34136c7b2ad04d4472dd9ea86536f5e9fb71fb0eb78edc8dad76a3f9edf2/srsly-0.2.0-cp36-cp36m-manylinux1_x86_64.whl (185kB)\n",
      "\u001b[K    100% |████████████████████████████████| 194kB 42.6MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting tqdm<5.0.0,>=4.10.0 (from thinc<7.4.0,>=7.3.0->spacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/13/cd55c23e3e158ed5b87cae415ee3844fc54cb43803fa3a0a064d23ecb883/tqdm-4.40.0-py2.py3-none-any.whl (54kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 32.1MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting importlib-metadata>=0.20; python_version < \"3.8\" (from catalogue<1.1.0,>=0.0.7->spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/ed/82/ebece33bc20b9097683d09e47563d487e411e2cf3a37789d7ec0a88c4ce4/importlib_metadata-1.1.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.23)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Collecting zipp>=0.5 (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/74/3d/1ee25a26411ba0401b43c6376d2316a71addcc72ef8690b101b4ea56d76a/zipp-0.6.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: more-itertools in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (4.1.0)\n",
      "Requirement already satisfied: six<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from more-itertools->zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (1.11.0)\n",
      "Installing collected packages: plac, numpy, murmurhash, srsly, tqdm, blis, cymem, wasabi, preshed, thinc, zipp, importlib-metadata, catalogue, spacy\n",
      "  Found existing installation: numpy 1.14.3\n",
      "    Uninstalling numpy-1.14.3:\n",
      "      Successfully uninstalled numpy-1.14.3\n",
      "Successfully installed blis-0.4.1 catalogue-0.0.8 cymem-2.0.3 importlib-metadata-1.1.0 murmurhash-1.0.2 numpy-1.17.4 plac-1.1.3 preshed-3.0.2 spacy-2.2.3 srsly-0.2.0 thinc-7.3.1 tqdm-4.40.0 wasabi-0.4.2 zipp-0.6.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting en_core_web_lg==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz#egg=en_core_web_lg==2.2.5\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 827.9MB 79.4MB/s ta 0:00:011    39% |████████████▊                   | 328.6MB 57.1MB/s eta 0:00:09   | 393.8MB 69.1MB/s eta 0:00:07    56% |██████████████████              | 465.2MB 69.1MB/s eta 0:00:06��████████████████▎        | 602.5MB 77.8MB/s eta 0:00:03��████████████████▍    | 708.3MB 72.1MB/s eta 0:00:02    97% |███████████████████████████████▏| 806.8MB 86.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from en_core_web_lg==2.2.5) (2.2.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (39.1.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.17.4)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.20.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.2.0)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.3.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.0)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2019.9.11)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.23)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (4.40.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (4.1.0)\n",
      "Requirement already satisfied: six<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from more-itertools->zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.11.0)\n",
      "Installing collected packages: en-core-web-lg\n",
      "  Running setup.py install for en-core-web-lg ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed en-core-web-lg-2.2.5\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "!pip install category_encoders\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize.regexp import regexp_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "\n",
    "role = get_execution_role()\n",
    "bucket='sagemaker-tagger'\n",
    "data_key1 = 'update_twelve_three.csv'\n",
    "data_location1 = 's3://{}/{}'.format(bucket, data_key1)\n",
    "\n",
    "df = pd.read_csv(data_location1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>Message</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Tags</th>\n",
       "      <th>UID</th>\n",
       "      <th>text</th>\n",
       "      <th>tag_list</th>\n",
       "      <th>first_tag</th>\n",
       "      <th>sender_name</th>\n",
       "      <th>sender_email</th>\n",
       "      <th>domain_name</th>\n",
       "      <th>isNoReply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;grangepayments@westernunionspeedpay.com&gt;</td>\n",
       "      <td>Dear AVRAHAM JACOBSOHN,  This is to confirm th...</td>\n",
       "      <td>Grange Payment Confirmation</td>\n",
       "      <td>Finance</td>\n",
       "      <td>31780</td>\n",
       "      <td>&lt;grangepayments@westernunionspeedpay.com&gt; Gran...</td>\n",
       "      <td>['Finance']</td>\n",
       "      <td>Finance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grangepayments@westernunionspeedpay.com</td>\n",
       "      <td>westernunionspeedpay</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chase &lt;no.reply.alerts@chase.com&gt;</td>\n",
       "      <td>This is an Alert to help manage your account ...</td>\n",
       "      <td>Your Debit Card Transaction</td>\n",
       "      <td>Finance</td>\n",
       "      <td>31779</td>\n",
       "      <td>Chase &lt;no.reply.alerts@chase.com&gt; Your Debit C...</td>\n",
       "      <td>['Finance']</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Chase</td>\n",
       "      <td>no.reply.alerts@chase.com</td>\n",
       "      <td>chase</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon Web Services &lt;no-reply-aws@amazon.com&gt;</td>\n",
       "      <td>Please let us know if we helped resolve your i...</td>\n",
       "      <td>Resolved 6559329691: Limit Increase: SageMaker</td>\n",
       "      <td>Productivity</td>\n",
       "      <td>31738</td>\n",
       "      <td>Amazon Web Services &lt;no-reply-aws@amazon.com&gt; ...</td>\n",
       "      <td>['Productivity']</td>\n",
       "      <td>Productivity</td>\n",
       "      <td>Amazon Web Services</td>\n",
       "      <td>no-reply-aws@amazon.com</td>\n",
       "      <td>amazon</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lambda Labs &lt;noreply@github.com&gt;</td>\n",
       "      <td>Youve been added to the Labs 18 - Tagger team ...</td>\n",
       "      <td>Bernie Durfee added you to the Lambda Labs tea...</td>\n",
       "      <td>Productivity</td>\n",
       "      <td>31693</td>\n",
       "      <td>Lambda Labs &lt;noreply@github.com&gt; Bernie Durfee...</td>\n",
       "      <td>['Productivity']</td>\n",
       "      <td>Productivity</td>\n",
       "      <td>Lambda Labs</td>\n",
       "      <td>noreply@github.com</td>\n",
       "      <td>github</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon Web Services &lt;no-reply-aws@amazon.com&gt;</td>\n",
       "      <td>Hello,  We haven't heard back from you regard...</td>\n",
       "      <td>Attention required on case 6559329691: Limit I...</td>\n",
       "      <td>Productivity</td>\n",
       "      <td>31684</td>\n",
       "      <td>Amazon Web Services &lt;no-reply-aws@amazon.com&gt; ...</td>\n",
       "      <td>['Productivity']</td>\n",
       "      <td>Productivity</td>\n",
       "      <td>Amazon Web Services</td>\n",
       "      <td>no-reply-aws@amazon.com</td>\n",
       "      <td>amazon</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            From  \\\n",
       "0      <grangepayments@westernunionspeedpay.com>   \n",
       "1              Chase <no.reply.alerts@chase.com>   \n",
       "2  Amazon Web Services <no-reply-aws@amazon.com>   \n",
       "3               Lambda Labs <noreply@github.com>   \n",
       "4  Amazon Web Services <no-reply-aws@amazon.com>   \n",
       "\n",
       "                                             Message  \\\n",
       "0  Dear AVRAHAM JACOBSOHN,  This is to confirm th...   \n",
       "1   This is an Alert to help manage your account ...   \n",
       "2  Please let us know if we helped resolve your i...   \n",
       "3  Youve been added to the Labs 18 - Tagger team ...   \n",
       "4   Hello,  We haven't heard back from you regard...   \n",
       "\n",
       "                                             Subject          Tags    UID  \\\n",
       "0                        Grange Payment Confirmation       Finance  31780   \n",
       "1                        Your Debit Card Transaction       Finance  31779   \n",
       "2     Resolved 6559329691: Limit Increase: SageMaker  Productivity  31738   \n",
       "3  Bernie Durfee added you to the Lambda Labs tea...  Productivity  31693   \n",
       "4  Attention required on case 6559329691: Limit I...  Productivity  31684   \n",
       "\n",
       "                                                text          tag_list  \\\n",
       "0  <grangepayments@westernunionspeedpay.com> Gran...       ['Finance']   \n",
       "1  Chase <no.reply.alerts@chase.com> Your Debit C...       ['Finance']   \n",
       "2  Amazon Web Services <no-reply-aws@amazon.com> ...  ['Productivity']   \n",
       "3  Lambda Labs <noreply@github.com> Bernie Durfee...  ['Productivity']   \n",
       "4  Amazon Web Services <no-reply-aws@amazon.com> ...  ['Productivity']   \n",
       "\n",
       "      first_tag          sender_name                             sender_email  \\\n",
       "0       Finance                  NaN  grangepayments@westernunionspeedpay.com   \n",
       "1       Finance                Chase                no.reply.alerts@chase.com   \n",
       "2  Productivity  Amazon Web Services                  no-reply-aws@amazon.com   \n",
       "3  Productivity          Lambda Labs                       noreply@github.com   \n",
       "4  Productivity  Amazon Web Services                  no-reply-aws@amazon.com   \n",
       "\n",
       "            domain_name  isNoReply  \n",
       "0  westernunionspeedpay      False  \n",
       "1                 chase       True  \n",
       "2                amazon       True  \n",
       "3                github       True  \n",
       "4                amazon       True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3732404\n"
     ]
    }
   ],
   "source": [
    "# Applying length of messages as feature\n",
    "\n",
    "df['Text_Length'] = df['Message'].apply(str)\n",
    "df['Text_Length'] = df['Text_Length'].apply(len)\n",
    "print(df['Text_Length'].min(), df['Text_Length'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean the text prior to tokenizing\n",
    "\n",
    "def clean_text(text):\n",
    "    # Perform a few cleaning steps to remove non-alphabetic characters\n",
    "    \n",
    "    text = text.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    \n",
    "    text = text.strip(\" \")\n",
    "    \n",
    "    punc_list = '!@#$%^&*()+?-_=:.<>[]{}/\\~\",' + '1234567890'\n",
    "    t = str.maketrans(dict.fromkeys(punc_list, \" \"))\n",
    "    text = text.translate(t)\n",
    "    \n",
    "    return text\n",
    "\n",
    "df['Clean_Message'] = (df['text'].apply(clean_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 3732441\n"
     ]
    }
   ],
   "source": [
    "# Applying length of CLEAN messages as feature\n",
    "\n",
    "df['Clean_Text_Length'] = df['Clean_Message'].apply(len)\n",
    "print(df['Clean_Text_Length'].min(), df['Clean_Text_Length'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     10532\n",
       "False      666\n",
       "Name: Clean_Text_Length, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most lengths are below 5000 even with a max of 370k length\n",
    "\n",
    "clean_text_length = df['Clean_Text_Length'] < 5000\n",
    "clean_text_length.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8958,), (2240,), (8958,), (2240,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df['Clean_Message']\n",
    "y = df['first_tag']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def regnltk_tokenize(text):\n",
    "    text = clean_text(text)\n",
    "    words = regexp_tokenize(text, pattern = '\\s+', gaps = True)\n",
    "    return [lemmatizer.lemmatize(word.lower()) for word in words if (len(word) >= 3)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Two Plus Two Poker Forums   forum master twoplustwo com   Merge Network  Carbon  Sportsbook  PlayersOnly   Deposit  Withdrawal Thread  update Dear noreallyimfine   You are subscribed to the thread  Merge Network  Carbon  Sportsbook  PlayersOnly   Deposit  Withdrawal Thread  by kahntrutahn  there have been   post s  to this thread  the last poster was highinaroom  http   forumserver twoplustwo com showthread php t          These following posts were made to the thread               Re  Merge Network  Carbon  Sportsbook  PlayersOnly   Deposit  Withdrawal Thread http   forumserver twoplustwo com showthread php p          post         Posted by  highinaroom On                   AM  So I had Circle to move funds from Blockchain to my bank account but Circle stopped doing this  What's the alternative to Circle now               Re  Merge Network  Carbon  Sportsbook  PlayersOnly   Deposit  Withdrawal Thread http   forumserver twoplustwo com showthread php p          post         Posted by  goodsaint On                   PM      Quote  Originally by highinaroom     So I had Circle to move funds from Blockchain to my bank account but Circle stopped doing this  What's the alternative to Circle now     End Quote    Coinbase is the financial exchange of choice for many now  Visa bitpay card is also an attractive option  Can withdraw funds from ATMs for minimal fees or get cash back from purchases where any Visa debit card is accepted for no fee  Some of us have also continued to cash out funds via Circle by using a PREVIOUSLY USED CIRCLE GENERATED ADDRESS to transfer from Blockchain to Circle  Did     such cash outs after Circle stopped providing bitcoin addresses  Haven't done any in   months since getting the bitpay card  Don't know if the loophole is still viable               Re  Merge Network  Carbon  Sportsbook  PlayersOnly   Deposit  Withdrawal Thread http   forumserver twoplustwo com showthread php p          post         Posted by  highinaroom On                   PM      Quote  Originally by goodsaint     Coinbase is the financial exchange of choice for many now  Visa bitpay card is also an attractive option  Can withdraw funds from ATMs for minimal fees or get cash back from purchases where any Visa debit card is accepted for no fee  Some of us have also continued to cash out funds via Circle by using a PREVIOUSLY USED CIRCLE GENERATED ADDRESS to transfer from Blockchain to Circle  Did     such cash outs after Circle stopped providing bitcoin addresses  Haven't done any in   months since getting the bitpay card  Don't know if the loophole is still viable     End Quote    Bitpay cc looks perfect  Thanks    All the best  Two Plus Two Poker Forums                                        Unsubscription information   To unsubscribe from this thread  please visit this page  http   forumserver twoplustwo com subscription php do removesubscription type thread subscriptionid         auth   feaeb  d bda c  d  cd     b   \""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer(tokenizer=regnltk_tokenize, min_df=0.03, max_df=0.98, stop_words='english')\n",
    "X_train = vect.fit_transform(X_train)\n",
    "X_test = vect.transform(X_test)\n",
    "\n",
    "encoder = ce.OrdinalEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting LSTM set-up with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
      "\u001b[K    100% |████████████████████████████████| 378kB 25.3MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from keras) (2.8.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from keras) (3.12)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from keras) (1.11.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from keras) (1.17.4)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from keras) (1.1.0)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.3.1\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 443652 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# Starting tokenizing from keras preprocessing\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(df['Clean_Message'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (11198, 5000)\n"
     ]
    }
   ],
   "source": [
    "X_LSTM = tokenizer.texts_to_sequences(df['Clean_Message'].values)\n",
    "X_LSTM = pad_sequences(X_LSTM, maxlen=5000)\n",
    "print('Shape of data tensor:', X_LSTM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (11198, 8)\n"
     ]
    }
   ],
   "source": [
    "Y_LSTM = pd.get_dummies(df['first_tag']).values\n",
    "print('Shape of label tensor:', Y_LSTM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10078, 5000) (10078, 8)\n",
      "(1120, 5000) (1120, 8)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_LSTM,Y_LSTM, test_size = 0.10, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 5000, 100)         500000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 5000, 100)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 808       \n",
      "=================================================================\n",
      "Total params: 581,208\n",
      "Trainable params: 581,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(5000, 100, input_length=X_LSTM.shape[1]))\n",
    "model.add(SpatialDropout1D(0.15))\n",
    "model.add(LSTM(100, dropout=0.15, recurrent_dropout=0.15))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "batch_size = 8\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
