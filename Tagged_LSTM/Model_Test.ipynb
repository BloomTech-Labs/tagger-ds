{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AhaWewB3itRZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, GRU\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout, SpatialDropout1D, Input, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "UD6iZMIALJ8H",
    "outputId": "0e3ccf63-f1a3-46c1-e9f7-391ff31a155b"
   },
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "bucket='sagemaker-tagger'\n",
    "data_key1 = 'update_twelve_three.csv'\n",
    "data_location1 = 's3://{}/{}'.format(bucket, data_key1)\n",
    "\n",
    "df = pd.read_csv(data_location1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "qm1usu18VrKN",
    "outputId": "da4abaa4-95d2-4a07-aa2d-ae0a195540e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dear AVRAHAM JACOBSOHN,  This is to confirm that a card payment for 142.48 was made to your Grange account ending in 1173 using the card ending in 2308.  Confirmation Number: 6786423  Scheduled Payment Date: 11/08/2019  Payment Amount: 142.48  Last 4 of Card: 2308  Please contact Grange Insurance at 1-800-425-1100 if you have any questions.  Sincerely,  Grange Insurance  Please note:  This email message was sent from a notification-only address that cannot accept incoming email.  Please do not reply to this message.  '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Message'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LxhryVWcdwzX"
   },
   "outputs": [],
   "source": [
    "# Change the name of the column with From + Subject + Message\n",
    "\n",
    "df.rename(columns={'text':'Combined_Text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VEhxUZs4GxTl"
   },
   "outputs": [],
   "source": [
    "# Function to clean the text prior to tokenizing\n",
    "\n",
    "def clean_text(text):\n",
    "    # Perform a few cleaning steps to remove non-alphabetic characters\n",
    "    \n",
    "    text = text.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "\n",
    "    text = text.strip(\" \")\n",
    "    \n",
    "    punc_list = '!@#$%^&*()+?-_=:.<>[]{}/\\~\",Â©' + '1234567890'\n",
    "    t = str.maketrans(dict.fromkeys(punc_list, \" \"))\n",
    "    text = text.translate(t)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MqwHdyjfWM1U"
   },
   "outputs": [],
   "source": [
    "# Clean the From Message and Subject before separating to different models\n",
    "\n",
    "df['Clean_Message'] = df['Message'].apply(clean_text)\n",
    "\n",
    "df['Clean_From'] = df['From'].apply(clean_text)\n",
    "\n",
    "df['Clean_Subject'] = df['Subject'].apply(clean_text)\n",
    "\n",
    "df['Combined_Text'] = df['Combined_Text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 534
    },
    "colab_type": "code",
    "id": "bS_B87XnWOk0",
    "outputId": "ac38643d-3b0d-4caa-f8b8-7ffc9504d73a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>Message</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Tags</th>\n",
       "      <th>UID</th>\n",
       "      <th>Combined_Text</th>\n",
       "      <th>tag_list</th>\n",
       "      <th>first_tag</th>\n",
       "      <th>sender_name</th>\n",
       "      <th>sender_email</th>\n",
       "      <th>domain_name</th>\n",
       "      <th>isNoReply</th>\n",
       "      <th>Clean_Message</th>\n",
       "      <th>Clean_From</th>\n",
       "      <th>Clean_Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;grangepayments@westernunionspeedpay.com&gt;</td>\n",
       "      <td>Dear AVRAHAM JACOBSOHN,  This is to confirm th...</td>\n",
       "      <td>Grange Payment Confirmation</td>\n",
       "      <td>Finance</td>\n",
       "      <td>31780</td>\n",
       "      <td>grangepayments westernunionspeedpay com  Gran...</td>\n",
       "      <td>['Finance']</td>\n",
       "      <td>Finance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grangepayments@westernunionspeedpay.com</td>\n",
       "      <td>westernunionspeedpay</td>\n",
       "      <td>False</td>\n",
       "      <td>Dear AVRAHAM JACOBSOHN   This is to confirm th...</td>\n",
       "      <td>grangepayments westernunionspeedpay com</td>\n",
       "      <td>Grange Payment Confirmation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chase &lt;no.reply.alerts@chase.com&gt;</td>\n",
       "      <td>This is an Alert to help manage your account ...</td>\n",
       "      <td>Your Debit Card Transaction</td>\n",
       "      <td>Finance</td>\n",
       "      <td>31779</td>\n",
       "      <td>Chase  no reply alerts chase com  Your Debit C...</td>\n",
       "      <td>['Finance']</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Chase</td>\n",
       "      <td>no.reply.alerts@chase.com</td>\n",
       "      <td>chase</td>\n",
       "      <td>True</td>\n",
       "      <td>This is an Alert to help manage your account e...</td>\n",
       "      <td>Chase  no reply alerts chase com</td>\n",
       "      <td>Your Debit Card Transaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon Web Services &lt;no-reply-aws@amazon.com&gt;</td>\n",
       "      <td>Please let us know if we helped resolve your i...</td>\n",
       "      <td>Resolved 6559329691: Limit Increase: SageMaker</td>\n",
       "      <td>Productivity</td>\n",
       "      <td>31738</td>\n",
       "      <td>Amazon Web Services  no reply aws amazon com  ...</td>\n",
       "      <td>['Productivity']</td>\n",
       "      <td>Productivity</td>\n",
       "      <td>Amazon Web Services</td>\n",
       "      <td>no-reply-aws@amazon.com</td>\n",
       "      <td>amazon</td>\n",
       "      <td>True</td>\n",
       "      <td>Please let us know if we helped resolve your i...</td>\n",
       "      <td>Amazon Web Services  no reply aws amazon com</td>\n",
       "      <td>Resolved             Limit Increase  SageMaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lambda Labs &lt;noreply@github.com&gt;</td>\n",
       "      <td>Youve been added to the Labs 18 - Tagger team ...</td>\n",
       "      <td>Bernie Durfee added you to the Lambda Labs tea...</td>\n",
       "      <td>Productivity</td>\n",
       "      <td>31693</td>\n",
       "      <td>Lambda Labs  noreply github com  Bernie Durfee...</td>\n",
       "      <td>['Productivity']</td>\n",
       "      <td>Productivity</td>\n",
       "      <td>Lambda Labs</td>\n",
       "      <td>noreply@github.com</td>\n",
       "      <td>github</td>\n",
       "      <td>True</td>\n",
       "      <td>Youve been added to the Labs      Tagger team ...</td>\n",
       "      <td>Lambda Labs  noreply github com</td>\n",
       "      <td>Bernie Durfee added you to the Lambda Labs tea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon Web Services &lt;no-reply-aws@amazon.com&gt;</td>\n",
       "      <td>Hello,  We haven't heard back from you regard...</td>\n",
       "      <td>Attention required on case 6559329691: Limit I...</td>\n",
       "      <td>Productivity</td>\n",
       "      <td>31684</td>\n",
       "      <td>Amazon Web Services  no reply aws amazon com  ...</td>\n",
       "      <td>['Productivity']</td>\n",
       "      <td>Productivity</td>\n",
       "      <td>Amazon Web Services</td>\n",
       "      <td>no-reply-aws@amazon.com</td>\n",
       "      <td>amazon</td>\n",
       "      <td>True</td>\n",
       "      <td>Hello   We haven't heard back from you regardi...</td>\n",
       "      <td>Amazon Web Services  no reply aws amazon com</td>\n",
       "      <td>Attention required on case             Limit I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            From  \\\n",
       "0      <grangepayments@westernunionspeedpay.com>   \n",
       "1              Chase <no.reply.alerts@chase.com>   \n",
       "2  Amazon Web Services <no-reply-aws@amazon.com>   \n",
       "3               Lambda Labs <noreply@github.com>   \n",
       "4  Amazon Web Services <no-reply-aws@amazon.com>   \n",
       "\n",
       "                                             Message  \\\n",
       "0  Dear AVRAHAM JACOBSOHN,  This is to confirm th...   \n",
       "1   This is an Alert to help manage your account ...   \n",
       "2  Please let us know if we helped resolve your i...   \n",
       "3  Youve been added to the Labs 18 - Tagger team ...   \n",
       "4   Hello,  We haven't heard back from you regard...   \n",
       "\n",
       "                                             Subject          Tags    UID  \\\n",
       "0                        Grange Payment Confirmation       Finance  31780   \n",
       "1                        Your Debit Card Transaction       Finance  31779   \n",
       "2     Resolved 6559329691: Limit Increase: SageMaker  Productivity  31738   \n",
       "3  Bernie Durfee added you to the Lambda Labs tea...  Productivity  31693   \n",
       "4  Attention required on case 6559329691: Limit I...  Productivity  31684   \n",
       "\n",
       "                                       Combined_Text          tag_list  \\\n",
       "0   grangepayments westernunionspeedpay com  Gran...       ['Finance']   \n",
       "1  Chase  no reply alerts chase com  Your Debit C...       ['Finance']   \n",
       "2  Amazon Web Services  no reply aws amazon com  ...  ['Productivity']   \n",
       "3  Lambda Labs  noreply github com  Bernie Durfee...  ['Productivity']   \n",
       "4  Amazon Web Services  no reply aws amazon com  ...  ['Productivity']   \n",
       "\n",
       "      first_tag          sender_name                             sender_email  \\\n",
       "0       Finance                  NaN  grangepayments@westernunionspeedpay.com   \n",
       "1       Finance                Chase                no.reply.alerts@chase.com   \n",
       "2  Productivity  Amazon Web Services                  no-reply-aws@amazon.com   \n",
       "3  Productivity          Lambda Labs                       noreply@github.com   \n",
       "4  Productivity  Amazon Web Services                  no-reply-aws@amazon.com   \n",
       "\n",
       "            domain_name  isNoReply  \\\n",
       "0  westernunionspeedpay      False   \n",
       "1                 chase       True   \n",
       "2                amazon       True   \n",
       "3                github       True   \n",
       "4                amazon       True   \n",
       "\n",
       "                                       Clean_Message  \\\n",
       "0  Dear AVRAHAM JACOBSOHN   This is to confirm th...   \n",
       "1  This is an Alert to help manage your account e...   \n",
       "2  Please let us know if we helped resolve your i...   \n",
       "3  Youve been added to the Labs      Tagger team ...   \n",
       "4  Hello   We haven't heard back from you regardi...   \n",
       "\n",
       "                                      Clean_From  \\\n",
       "0       grangepayments westernunionspeedpay com    \n",
       "1              Chase  no reply alerts chase com    \n",
       "2  Amazon Web Services  no reply aws amazon com    \n",
       "3               Lambda Labs  noreply github com    \n",
       "4  Amazon Web Services  no reply aws amazon com    \n",
       "\n",
       "                                       Clean_Subject  \n",
       "0                        Grange Payment Confirmation  \n",
       "1                        Your Debit Card Transaction  \n",
       "2     Resolved             Limit Increase  SageMaker  \n",
       "3  Bernie Durfee added you to the Lambda Labs tea...  \n",
       "4  Attention required on case             Limit I...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 603
    },
    "colab_type": "code",
    "id": "0fNuPHE1SdLi",
    "outputId": "2d681018-0d84-46e4-c74b-b1b1dd8c526b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Finance']                      5604\n",
       "['Entertainment']                1505\n",
       "['Shopping']                     1065\n",
       "['Personal', 'Other']             685\n",
       "['Productivity']                  514\n",
       "['Other']                         514\n",
       "['Personal', 'Productivity']      382\n",
       "['Social']                        146\n",
       "['Productivity', 'Events']        130\n",
       "['Entertainment', 'Finance']      102\n",
       "['Personal', 'Events']             95\n",
       "['Personal', 'Shopping']           95\n",
       "['Events']                         95\n",
       "['Travel']                         92\n",
       "['Personal', 'Finance']            69\n",
       "['Personal', 'Travel']             25\n",
       "['Personal', 'Entertainment']      19\n",
       "['Shopping', 'Finance']            13\n",
       "['Entertainment', 'Shopping']      10\n",
       "['Events', 'Productivity']          8\n",
       "['Travel', 'Finance']               5\n",
       "['Shopping', 'Entertainment']       4\n",
       "['Social', 'Productivity']          4\n",
       "['Productivity', 'Finance']         4\n",
       "['Personal', 'Social']              4\n",
       "['Shopping', 'Productivity']        2\n",
       "['Finance', 'Travel']               2\n",
       "['Events', 'Entertainment']         1\n",
       "['Productivity', 'Shopping']        1\n",
       "['Finance', 'Productivity']         1\n",
       "['Finance', 'Events']               1\n",
       "['Finance', 'Shopping']             1\n",
       "Name: tag_list, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tag_list'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 603
    },
    "colab_type": "code",
    "id": "ph6GGRbdSyzm",
    "outputId": "13939edc-b2f3-4f2e-db23-d9061a09d496"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Finance                    5604\n",
       "Entertainment              1505\n",
       "Shopping                   1065\n",
       "Personal, Other             685\n",
       "Productivity                514\n",
       "Other                       514\n",
       "Personal, Productivity      382\n",
       "Social                      146\n",
       "Productivity, Events        130\n",
       "Entertainment, Finance      102\n",
       "Personal, Events             95\n",
       "Personal, Shopping           95\n",
       "Events                       95\n",
       "Travel                       92\n",
       "Personal, Finance            69\n",
       "Personal, Travel             25\n",
       "Personal, Entertainment      19\n",
       "Shopping, Finance            13\n",
       "Entertainment, Shopping      10\n",
       "Events, Productivity          8\n",
       "Travel, Finance               5\n",
       "Social, Productivity          4\n",
       "Personal, Social              4\n",
       "Productivity, Finance         4\n",
       "Shopping, Entertainment       4\n",
       "Shopping, Productivity        2\n",
       "Finance, Travel               2\n",
       "Finance, Shopping             1\n",
       "Productivity, Shopping        1\n",
       "Events, Entertainment         1\n",
       "Finance, Productivity         1\n",
       "Finance, Events               1\n",
       "Name: Tags, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tags'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "kj2T37nOSmu_",
    "outputId": "8b48f09d-f4b6-4885-977d-04fbba43e133"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    9824\n",
       "True     1374\n",
       "Name: Personal, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Personal Column\n",
    "\n",
    "df['Personal'] = df['Tags'].str.contains('Personal')\n",
    "df['Personal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gaBzqwYYG0jA",
    "outputId": "04cee3d0-a0f8-4d15-ef3a-f7ea41139a0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3732402\n"
     ]
    }
   ],
   "source": [
    "# Applying length of CLEAN messages as feature\n",
    "\n",
    "df['Clean_Text_Length'] = df['Clean_Message'].apply(len)\n",
    "print(df['Clean_Text_Length'].min(), df['Clean_Text_Length'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "dp5Bj6JnG2Se",
    "outputId": "a7f4e25a-03e6-4993-d937-5ee411586cd4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     10544\n",
       "False      654\n",
       "Name: Clean_Text_Length, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most lengths are below 5000 even with a max of 370k length\n",
    "\n",
    "clean_text_length = df['Clean_Text_Length'] < 5000\n",
    "clean_text_length.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sEAN2_5PG39c"
   },
   "outputs": [],
   "source": [
    "# lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# def regnltk_tokenize(text):\n",
    "#     text = clean_text(text)\n",
    "#     words = regexp_tokenize(text, pattern = '\\s+', gaps = True)\n",
    "#     return [lemmatizer.lemmatize(word.lower()) for word in words if (len(word) >= 3)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dpfetY0tZNiF"
   },
   "outputs": [],
   "source": [
    "# Remove too small and too large texts from the messages before tokenizing\n",
    "\n",
    "message_values = df['Combined_Text'].values\n",
    "\n",
    "tokens = []\n",
    "\n",
    "for i in range(len(message_values)):\n",
    "    value = message_values[i]\n",
    "    value = value.split(\" \")\n",
    "    value = [x for x in value if len(x) > 3 and len(x) < 20]\n",
    "    value = \" \".join(value)\n",
    "    tokens.append(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6ERBtrKuIZHw"
   },
   "source": [
    "## Start of Keras Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QaH-6EDDG65r",
    "outputId": "f1753a97-70c0-4e42-8e03-3a489975ff70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 407235 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# Starting tokenizing from keras preprocessing\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True, split=' ')\n",
    "tokenizer.fit_on_texts(tokens)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "# saving\n",
    "with open('final_tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "crClksY_JpjS",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amazon': 1,\n",
       " 'payments': 2,\n",
       " 'http': 3,\n",
       " 'style': 4,\n",
       " 'width': 5,\n",
       " 'your': 6,\n",
       " 'from': 7,\n",
       " 'font': 8,\n",
       " 'payment': 9,\n",
       " 'https': 10,\n",
       " 'jacobsohn': 11,\n",
       " 'table': 12,\n",
       " 'align': 13,\n",
       " 'this': 14,\n",
       " 'border': 15,\n",
       " 'height': 16,\n",
       " 'please': 17,\n",
       " 'color': 18,\n",
       " 'jdeal': 19,\n",
       " 'class': 20,\n",
       " 'important': 21,\n",
       " 'kalman': 22,\n",
       " 'text': 23,\n",
       " 'sdui': 24,\n",
       " 'padding': 25,\n",
       " 'size': 26,\n",
       " 'information': 27,\n",
       " 'email': 28,\n",
       " 'about': 29,\n",
       " 'left': 30,\n",
       " 'none': 31,\n",
       " 'center': 32,\n",
       " 'help': 33,\n",
       " 'sent': 34,\n",
       " 'with': 35,\n",
       " 'reply': 36,\n",
       " 'visit': 37,\n",
       " 'family': 38,\n",
       " 'thank': 39,\n",
       " 'link': 40,\n",
       " 'have': 41,\n",
       " 'deal': 42,\n",
       " 'nbsp': 43,\n",
       " 'details': 44,\n",
       " 'thread': 45,\n",
       " 'using': 46,\n",
       " 'completed': 47,\n",
       " 'line': 48,\n",
       " 'display': 49,\n",
       " 'that': 50,\n",
       " 'note': 51,\n",
       " 'serif': 52,\n",
       " 'sans': 53,\n",
       " 'further': 54,\n",
       " 'avenue': 55,\n",
       " 'amount': 56,\n",
       " 'seattle': 57,\n",
       " 'cellpadding': 58,\n",
       " 'cellspacing': 59,\n",
       " 'pages': 60,\n",
       " 'north': 61,\n",
       " 'click': 62,\n",
       " 'greetings': 63,\n",
       " 'href': 64,\n",
       " 'received': 65,\n",
       " 'terry': 66,\n",
       " 'helptab': 67,\n",
       " 'span': 68,\n",
       " 'optional': 69,\n",
       " 'arial': 70,\n",
       " 'block': 71,\n",
       " 'withdrawal': 72,\n",
       " 'carbon': 73,\n",
       " 'deposit': 74,\n",
       " 'will': 75,\n",
       " 'decoration': 76,\n",
       " 'account': 77,\n",
       " 'twoplustwo': 78,\n",
       " 'merge': 79,\n",
       " 'message': 80,\n",
       " 'margin': 81,\n",
       " 'view': 82,\n",
       " 'px': 83,\n",
       " 'network': 84,\n",
       " 'more': 85,\n",
       " 'helvetica': 86,\n",
       " 'chave': 87,\n",
       " 'sportsbook': 88,\n",
       " 'weight': 89,\n",
       " 'forumserver': 90,\n",
       " 'playersonly': 91,\n",
       " 'gmail': 92,\n",
       " 'valign': 93,\n",
       " 'post': 94,\n",
       " 'right': 95,\n",
       " 'amp': 96,\n",
       " 'list': 97,\n",
       " 'deals': 98,\n",
       " 'value': 99,\n",
       " 'bgcolor': 100,\n",
       " 'showthread': 101,\n",
       " 'links': 102,\n",
       " 'recipient': 103,\n",
       " 'manage': 104,\n",
       " 'title': 105,\n",
       " 'successfully': 106,\n",
       " 'pokerstars': 107,\n",
       " 'target': 108,\n",
       " 'zwnj': 109,\n",
       " 'posted': 110,\n",
       " 'free': 111,\n",
       " 'mail': 112,\n",
       " 'wayfair': 113,\n",
       " 'quote': 114,\n",
       " 'yahoo': 115,\n",
       " 'source': 116,\n",
       " 'ffffff': 117,\n",
       " 'blank': 118,\n",
       " 'images': 119,\n",
       " 'support': 120,\n",
       " 'date': 121,\n",
       " 'mailto': 122,\n",
       " 'background': 123,\n",
       " 'unsubscribe': 124,\n",
       " 'york': 125,\n",
       " 'bottom': 126,\n",
       " 'medium': 127,\n",
       " 'they': 128,\n",
       " 'been': 129,\n",
       " 'tourney': 130,\n",
       " 'home': 131,\n",
       " 'html': 132,\n",
       " 'avraham': 133,\n",
       " 'time': 134,\n",
       " 'poker': 135,\n",
       " 'subject': 136,\n",
       " 'demail': 137,\n",
       " 'sender': 138,\n",
       " 'content': 139,\n",
       " 'shipping': 140,\n",
       " 'mobile': 141,\n",
       " 'here': 142,\n",
       " 'page': 143,\n",
       " 'brooklyn': 144,\n",
       " 'auto': 145,\n",
       " 'just': 146,\n",
       " 'jayjacobsohn': 147,\n",
       " 'chase': 148,\n",
       " 'nordstrom': 149,\n",
       " 'campaign': 150,\n",
       " 'dynamic': 151,\n",
       " 'other': 152,\n",
       " 'subscription': 153,\n",
       " 'vertical': 154,\n",
       " 'there': 155,\n",
       " 'normal': 156,\n",
       " 'check': 157,\n",
       " 'contact': 158,\n",
       " 'spacing': 159,\n",
       " 'body': 160,\n",
       " 'club': 161,\n",
       " 'like': 162,\n",
       " 'name': 163,\n",
       " 'tbody': 164,\n",
       " 'collapse': 165,\n",
       " 'dear': 166,\n",
       " 'facebook': 167,\n",
       " 'groupon': 168,\n",
       " 'these': 169,\n",
       " 'read': 170,\n",
       " 'original': 171,\n",
       " 'order': 172,\n",
       " 'only': 173,\n",
       " 'venue': 174,\n",
       " 'team': 175,\n",
       " 'data': 176,\n",
       " 'tournament': 177,\n",
       " 'online': 178,\n",
       " 'update': 179,\n",
       " 'available': 180,\n",
       " 'type': 181,\n",
       " 'receive': 182,\n",
       " 'best': 183,\n",
       " 'bold': 184,\n",
       " 'linkedin': 185,\n",
       " 'game': 186,\n",
       " 'card': 187,\n",
       " 'website': 188,\n",
       " 'address': 189,\n",
       " 'questions': 190,\n",
       " 'plus': 191,\n",
       " 'solid': 192,\n",
       " 'privacy': 193,\n",
       " 'originally': 194,\n",
       " 'top': 195,\n",
       " 'ecom': 196,\n",
       " 'division': 197,\n",
       " 'designsbyfmc': 198,\n",
       " 'when': 199,\n",
       " 'what': 200,\n",
       " 'would': 201,\n",
       " 'know': 202,\n",
       " 'today': 203,\n",
       " 'britishairways': 204,\n",
       " 'bank': 205,\n",
       " 'verdana': 206,\n",
       " 'make': 207,\n",
       " 'carbonpoker': 208,\n",
       " 'their': 209,\n",
       " 'last': 210,\n",
       " \"jaih's\": 211,\n",
       " 'emails': 212,\n",
       " 'dbbbb': 213,\n",
       " 'through': 214,\n",
       " 'twitter': 215,\n",
       " 'bitcoin': 216,\n",
       " 'worth': 217,\n",
       " 'also': 218,\n",
       " 'play': 219,\n",
       " 'secure': 220,\n",
       " 'year': 221,\n",
       " 'because': 222,\n",
       " 'need': 223,\n",
       " 'send': 224,\n",
       " 'services': 225,\n",
       " 'money': 226,\n",
       " 'them': 227,\n",
       " 'news': 228,\n",
       " 'receiving': 229,\n",
       " 'colspan': 230,\n",
       " 'connections': 231,\n",
       " 'image': 232,\n",
       " 'geneva': 233,\n",
       " 'following': 234,\n",
       " 'runitup': 235,\n",
       " 'transaction': 236,\n",
       " 'blackberry': 237,\n",
       " 'container': 238,\n",
       " 'spacer': 239,\n",
       " 'middle': 240,\n",
       " 'service': 241,\n",
       " 'days': 242,\n",
       " 'ddeal': 243,\n",
       " 'were': 244,\n",
       " 'find': 245,\n",
       " 'request': 246,\n",
       " 'jmedia': 247,\n",
       " 'thanks': 248,\n",
       " 'credit': 249,\n",
       " 'take': 250,\n",
       " 'alert': 251,\n",
       " 'college': 252,\n",
       " 'forums': 253,\n",
       " 'after': 254,\n",
       " 'strong': 255,\n",
       " 'first': 256,\n",
       " 'structure': 257,\n",
       " 'dnew': 258,\n",
       " 'requested': 259,\n",
       " 'made': 260,\n",
       " 'united': 261,\n",
       " \"neue'\": 262,\n",
       " 'policy': 263,\n",
       " 'notification': 264,\n",
       " 'site': 265,\n",
       " 'preferences': 266,\n",
       " 'still': 267,\n",
       " 'before': 268,\n",
       " \"'helvetica\": 269,\n",
       " 'some': 270,\n",
       " 'endif': 271,\n",
       " 'dbody': 272,\n",
       " \"don't\": 273,\n",
       " 'shell': 274,\n",
       " 'games': 275,\n",
       " 'week': 276,\n",
       " 'most': 277,\n",
       " 'logo': 278,\n",
       " 'over': 279,\n",
       " 'want': 280,\n",
       " 'back': 281,\n",
       " 'people': 282,\n",
       " 'button': 283,\n",
       " 'proj': 284,\n",
       " 'customer': 285,\n",
       " 'which': 286,\n",
       " 'track': 287,\n",
       " 'p': 288,\n",
       " 'full': 289,\n",
       " 'sure': 290,\n",
       " 'cuny': 291,\n",
       " 'scheduled': 292,\n",
       " 'including': 293,\n",
       " 'jewish': 294,\n",
       " 'skey': 295,\n",
       " 'israel': 296,\n",
       " 'change': 297,\n",
       " 'bclass': 298,\n",
       " 'kosher': 299,\n",
       " 'm': 300,\n",
       " 'footer': 301,\n",
       " 'enet': 302,\n",
       " 'should': 303,\n",
       " 'radius': 304,\n",
       " 'program': 305,\n",
       " 'call': 306,\n",
       " 'static': 307,\n",
       " 'then': 308,\n",
       " \"grande'\": 309,\n",
       " \"'lucida\": 310,\n",
       " 'tell': 311,\n",
       " 'below': 312,\n",
       " \"you're\": 313,\n",
       " 'under': 314,\n",
       " 'number': 315,\n",
       " 'business': 316,\n",
       " 'profile': 317,\n",
       " \"it's\": 318,\n",
       " 'shop': 319,\n",
       " 'office': 320,\n",
       " 'course': 321,\n",
       " 'phone': 322,\n",
       " 'good': 323,\n",
       " 'code': 324,\n",
       " 'than': 325,\n",
       " 'members': 326,\n",
       " 'newsletter': 327,\n",
       " 'media': 328,\n",
       " 'inline': 329,\n",
       " 'rowan': 330,\n",
       " 'sz': 331,\n",
       " 'hidden': 332,\n",
       " 'aicpch': 333,\n",
       " 'yamgjj': 334,\n",
       " 'user': 335,\n",
       " 'students': 336,\n",
       " 'into': 337,\n",
       " 'john': 338,\n",
       " \"'helveticaneue'\": 339,\n",
       " 'where': 340,\n",
       " 'share': 341,\n",
       " 'capitalone': 342,\n",
       " 'ecdn': 343,\n",
       " 'browser': 344,\n",
       " 'gift': 345,\n",
       " 'copy': 346,\n",
       " 'digest': 347,\n",
       " 'role': 348,\n",
       " 'street': 349,\n",
       " 'learn': 350,\n",
       " 'work': 351,\n",
       " 'zrtdbayogyh': 352,\n",
       " 'start': 353,\n",
       " 'google': 354,\n",
       " 'open': 355,\n",
       " 'jobs': 356,\n",
       " 'limit': 357,\n",
       " 'enjoy': 358,\n",
       " 'delivery': 359,\n",
       " 'tickets': 360,\n",
       " 'regards': 361,\n",
       " 'student': 362,\n",
       " 'wednesday': 363,\n",
       " 'hide': 364,\n",
       " 'presentation': 365,\n",
       " 'book': 366,\n",
       " 'located': 367,\n",
       " 'overflow': 368,\n",
       " 'blue': 369,\n",
       " 'webkit': 370,\n",
       " 'dchannel': 371,\n",
       " 'orders': 372,\n",
       " 'occasions': 373,\n",
       " 'month': 374,\n",
       " 'total': 375,\n",
       " 'eresponsys': 376,\n",
       " 'master': 377,\n",
       " 'monday': 378,\n",
       " 'think': 379,\n",
       " 'processed': 380,\n",
       " 'hours': 381,\n",
       " 'small': 382,\n",
       " 'players': 383,\n",
       " 'rights': 384,\n",
       " 'great': 385,\n",
       " 'epng': 386,\n",
       " 'place': 387,\n",
       " 'weekly': 388,\n",
       " 'does': 389,\n",
       " 'area': 390,\n",
       " 'noreallyimfine': 391,\n",
       " 'true': 392,\n",
       " 'info': 393,\n",
       " 'common': 394,\n",
       " 'apple': 395,\n",
       " 'posts': 396,\n",
       " 'transfer': 397,\n",
       " 'hdeyiornxj': 398,\n",
       " 'security': 399,\n",
       " 'well': 400,\n",
       " 'registered': 401,\n",
       " 'application': 402,\n",
       " 'terms': 403,\n",
       " 'responsysimages': 404,\n",
       " 'thursday': 405,\n",
       " 'going': 406,\n",
       " 'updates': 407,\n",
       " 'item': 408,\n",
       " 'food': 409,\n",
       " 'failed': 410,\n",
       " 'reserved': 411,\n",
       " 'signed': 412,\n",
       " 'offer': 413,\n",
       " 'head': 414,\n",
       " 'school': 415,\n",
       " 'savings': 416,\n",
       " 'purchase': 417,\n",
       " 'subscriptions': 418,\n",
       " 'next': 419,\n",
       " 'space': 420,\n",
       " 'social': 421,\n",
       " 'wfcdn': 422,\n",
       " 'look': 423,\n",
       " 'each': 424,\n",
       " 'password': 425,\n",
       " 'compr': 426,\n",
       " 'provide': 427,\n",
       " 'forum': 428,\n",
       " 'funds': 429,\n",
       " 'capital': 430,\n",
       " 'freecodecamp': 431,\n",
       " 'xhtml': 432,\n",
       " 'turn': 433,\n",
       " 'friday': 434,\n",
       " 'white': 435,\n",
       " 'subscribed': 436,\n",
       " 'underline': 437,\n",
       " 'november': 438,\n",
       " 'apply': 439,\n",
       " 'wine': 440,\n",
       " 'float': 441,\n",
       " 'dfalse': 442,\n",
       " 'fees': 443,\n",
       " 'donation': 444,\n",
       " 'wrapper': 445,\n",
       " 'defau': 446,\n",
       " 'israeli': 447,\n",
       " 'product': 448,\n",
       " 'world': 449,\n",
       " 'discount': 450,\n",
       " 'feel': 451,\n",
       " 'complete': 452,\n",
       " 'long': 453,\n",
       " 'magazine': 454,\n",
       " 'meta': 455,\n",
       " 'confirmation': 456,\n",
       " 'could': 457,\n",
       " 'leader': 458,\n",
       " 'much': 459,\n",
       " 'brought': 460,\n",
       " 'every': 461,\n",
       " 'option': 462,\n",
       " 'many': 463,\n",
       " 'stop': 464,\n",
       " 'within': 465,\n",
       " \"today's\": 466,\n",
       " 'choice': 467,\n",
       " 'wire': 468,\n",
       " 'listing': 469,\n",
       " 'auth': 470,\n",
       " 'ticket': 471,\n",
       " 'fwww': 472,\n",
       " 'kahntrutahn': 473,\n",
       " 'confirm': 474,\n",
       " 'download': 475,\n",
       " 'poster': 476,\n",
       " 'samuel': 477,\n",
       " 'enter': 478,\n",
       " 'follow': 479,\n",
       " 'dhttp': 480,\n",
       " 'included': 481,\n",
       " 'manager': 482,\n",
       " 'better': 483,\n",
       " 'wrote': 484,\n",
       " 'cash': 485,\n",
       " 'save': 486,\n",
       " 'america': 487,\n",
       " 'city': 488,\n",
       " 'statement': 489,\n",
       " 'aaaaaqa': 490,\n",
       " 'stores': 491,\n",
       " 'floor': 492,\n",
       " 'access': 493,\n",
       " 'ealerts': 494,\n",
       " 'again': 495,\n",
       " 'bothell': 496,\n",
       " 'room': 497,\n",
       " 'show': 498,\n",
       " 'very': 499,\n",
       " 'soon': 500,\n",
       " 'word': 501,\n",
       " 'unsubscription': 502,\n",
       " 'removesubscription': 503,\n",
       " 'subscriptionid': 504,\n",
       " 'feaeb': 505,\n",
       " 'started': 506,\n",
       " 'emailed': 507,\n",
       " 'store': 508,\n",
       " 'package': 509,\n",
       " 'adjust': 510,\n",
       " 'status': 511,\n",
       " 'cashier': 512,\n",
       " 'resize': 513,\n",
       " 'hawwuy': 514,\n",
       " \"'open\": 515,\n",
       " 'real': 516,\n",
       " 'sale': 517,\n",
       " 'hepner': 518,\n",
       " 'sales': 519,\n",
       " 'towards': 520,\n",
       " 'give': 521,\n",
       " 'term': 522,\n",
       " 'event': 523,\n",
       " 'monitored': 524,\n",
       " 'lobby': 525,\n",
       " 'icon': 526,\n",
       " 'seller': 527,\n",
       " 'prize': 528,\n",
       " 'mailbox': 529,\n",
       " 'things': 530,\n",
       " 'events': 531,\n",
       " 'sign': 532,\n",
       " 'circle': 533,\n",
       " 'wrap': 534,\n",
       " 'since': 535,\n",
       " 'username': 536,\n",
       " '\\t\\t\\t\\t': 537,\n",
       " 'alerts': 538,\n",
       " 'daily': 539,\n",
       " 'xmlns': 540,\n",
       " 'youtube': 541,\n",
       " 'both': 542,\n",
       " 'merchandising': 543,\n",
       " 'until': 544,\n",
       " 'life': 545,\n",
       " 'kids': 546,\n",
       " 'items': 547,\n",
       " 'times': 548,\n",
       " 'tuesday': 549,\n",
       " 'live': 550,\n",
       " 'dinner': 551,\n",
       " \"sans'\": 552,\n",
       " 'ending': 553,\n",
       " 'always': 554,\n",
       " 'down': 555,\n",
       " 'wfrcdn': 556,\n",
       " 'able': 557,\n",
       " 'bonus': 558,\n",
       " 'grouponcdn': 559,\n",
       " 'must': 560,\n",
       " 'everyone': 561,\n",
       " 'experience': 562,\n",
       " 'chance': 563,\n",
       " 'hello': 564,\n",
       " 'never': 565,\n",
       " 'review': 566,\n",
       " 'ship': 567,\n",
       " 'being': 568,\n",
       " 'cell': 569,\n",
       " 'process': 570,\n",
       " 'feedback': 571,\n",
       " 'keep': 572,\n",
       " 'pandora': 573,\n",
       " 'west': 574,\n",
       " 'assets': 575,\n",
       " 'banner': 576,\n",
       " 'screen': 577,\n",
       " 'points': 578,\n",
       " 'once': 579,\n",
       " 'same': 580,\n",
       " 'those': 581,\n",
       " 'ufnk': 582,\n",
       " 'amazing': 583,\n",
       " 'board': 584,\n",
       " 'award': 585,\n",
       " 'such': 586,\n",
       " \"hold'em\": 587,\n",
       " 'anyone': 588,\n",
       " 'products': 589,\n",
       " 'payout': 590,\n",
       " 'fwaxrhbg': 591,\n",
       " 'inbox': 592,\n",
       " 'reader': 593,\n",
       " 'personal': 594,\n",
       " 'june': 595,\n",
       " 'washington': 596,\n",
       " 'withdraw': 597,\n",
       " 'position': 598,\n",
       " 'column': 599,\n",
       " 'part': 600,\n",
       " 'getting': 601,\n",
       " 'come': 602,\n",
       " 'jmrzx': 603,\n",
       " 'stage': 604,\n",
       " 'reminder': 605,\n",
       " 'welcome': 606,\n",
       " 'even': 607,\n",
       " 'january': 608,\n",
       " 'hour': 609,\n",
       " 'fedex': 610,\n",
       " 'community': 611,\n",
       " 'friends': 612,\n",
       " 'python': 613,\n",
       " 'really': 614,\n",
       " 'dgcat': 615,\n",
       " 'summer': 616,\n",
       " 'noreply': 617,\n",
       " 'yourclub': 618,\n",
       " 'betting': 619,\n",
       " 'pool': 620,\n",
       " 'special': 621,\n",
       " 'blockchain': 622,\n",
       " 'used': 623,\n",
       " 'forward': 624,\n",
       " 'treatment': 625,\n",
       " 'weeks': 626,\n",
       " 'another': 627,\n",
       " 'set': 628,\n",
       " \"'schedule'\": 629,\n",
       " 'additional': 630,\n",
       " 'suite': 631,\n",
       " 'break': 632,\n",
       " 'october': 633,\n",
       " 'furniture': 634,\n",
       " 'wish': 635,\n",
       " 'balance': 636,\n",
       " 'description': 637,\n",
       " 'sunday': 638,\n",
       " 'around': 639,\n",
       " 'pending': 640,\n",
       " 'baemail': 641,\n",
       " 'dhbzoi': 642,\n",
       " 'cdovl': 643,\n",
       " 'months': 644,\n",
       " 'group': 645,\n",
       " 'offers': 646,\n",
       " 'drowan': 647,\n",
       " 'lookout': 648,\n",
       " 'files': 649,\n",
       " 'mylookout': 650,\n",
       " 'tracelog': 651,\n",
       " 'years': 652,\n",
       " 'minute': 653,\n",
       " 'three': 654,\n",
       " 'intended': 655,\n",
       " 'sailthru': 656,\n",
       " 'possible': 657,\n",
       " 'science': 658,\n",
       " 'public': 659,\n",
       " 'video': 660,\n",
       " 'null': 661,\n",
       " 'while': 662,\n",
       " 'withdrawals': 663,\n",
       " 'study': 664,\n",
       " 'instagram': 665,\n",
       " 'march': 666,\n",
       " 'member': 667,\n",
       " 'marketing': 668,\n",
       " 'inherit': 669,\n",
       " 'happy': 670,\n",
       " 'error': 671,\n",
       " 'results': 672,\n",
       " 'future': 673,\n",
       " 'during': 674,\n",
       " 'hope': 675,\n",
       " \"you'll\": 676,\n",
       " 'travel': 677,\n",
       " 'header': 678,\n",
       " 'already': 679,\n",
       " 'cancel': 680,\n",
       " 'debit': 681,\n",
       " 'love': 682,\n",
       " 'meet': 683,\n",
       " 'waiting': 684,\n",
       " 'fafd': 685,\n",
       " 'financial': 686,\n",
       " 'ight': 687,\n",
       " 'max': 688,\n",
       " 'said': 689,\n",
       " 'cost': 690,\n",
       " 'finished': 691,\n",
       " 'matched': 692,\n",
       " 'schedule': 693,\n",
       " 'aspx': 694,\n",
       " 'december': 695,\n",
       " 'usually': 696,\n",
       " 'nowrap': 697,\n",
       " 'plan': 698,\n",
       " 'normally': 699,\n",
       " 'ready': 700,\n",
       " 'regular': 701,\n",
       " 'notifications': 702,\n",
       " 'state': 703,\n",
       " 'ycmlzb': 704,\n",
       " 'regarding': 705,\n",
       " 'night': 706,\n",
       " 'main': 707,\n",
       " 'february': 708,\n",
       " 'morrison': 709,\n",
       " \"that's\": 710,\n",
       " 'join': 711,\n",
       " 'custom': 712,\n",
       " 'android': 713,\n",
       " 'courses': 714,\n",
       " 'paid': 715,\n",
       " 'vcnjpc': 716,\n",
       " 'high': 717,\n",
       " 'away': 718,\n",
       " 'company': 719,\n",
       " 'case': 720,\n",
       " 'watch': 721,\n",
       " 'spend': 722,\n",
       " 'recent': 723,\n",
       " 'tyle': 724,\n",
       " 'clear': 725,\n",
       " 'dnewsletter': 726,\n",
       " 'children': 727,\n",
       " 'gifts': 728,\n",
       " 'longer': 729,\n",
       " 'device': 730,\n",
       " 'return': 731,\n",
       " 'yourself': 732,\n",
       " 'anything': 733,\n",
       " 'april': 734,\n",
       " 'eunited': 735,\n",
       " 'wallet': 736,\n",
       " 'pycoders': 737,\n",
       " 'fraud': 738,\n",
       " 'dlink': 739,\n",
       " 'july': 740,\n",
       " 'search': 741,\n",
       " 'continue': 742,\n",
       " 'shipment': 743,\n",
       " 'middot': 744,\n",
       " 'registration': 745,\n",
       " 'design': 746,\n",
       " 'dimage': 747,\n",
       " 'aliexpress': 748,\n",
       " 'lambda': 749,\n",
       " 'someone': 750,\n",
       " 'merchant': 751,\n",
       " 'base': 752,\n",
       " 'iphone': 753,\n",
       " 'membership': 754,\n",
       " 'vwag': 755,\n",
       " 'cannot': 756,\n",
       " 'above': 757,\n",
       " 'standard': 758,\n",
       " 'congratulations': 759,\n",
       " 'little': 760,\n",
       " 'coinbase': 761,\n",
       " 'letter': 762,\n",
       " 'september': 763,\n",
       " 'correctly': 764,\n",
       " 'discountmags': 765,\n",
       " 'system': 766,\n",
       " 'looking': 767,\n",
       " 'niba': 768,\n",
       " 'nova': 769,\n",
       " 'goodsaint': 770,\n",
       " 'bankofamerica': 771,\n",
       " 'zzxbobw': 772,\n",
       " 'without': 773,\n",
       " 'price': 774,\n",
       " 'transitional': 775,\n",
       " 'career': 776,\n",
       " 'directly': 777,\n",
       " 'software': 778,\n",
       " 'microsoft': 779,\n",
       " 'side': 780,\n",
       " 'required': 781,\n",
       " 'series': 782,\n",
       " 'classes': 783,\n",
       " 'safe': 784,\n",
       " 'photo': 785,\n",
       " 'github': 786,\n",
       " 'file': 787,\n",
       " 'packages': 788,\n",
       " 'kitchen': 789,\n",
       " 'deefd': 790,\n",
       " 'problem': 791,\n",
       " 'might': 792,\n",
       " 'based': 793,\n",
       " 'golf': 794,\n",
       " 'bring': 795,\n",
       " 'having': 796,\n",
       " 'remoteok': 797,\n",
       " 'feature': 798,\n",
       " 'options': 799,\n",
       " 'participating': 800,\n",
       " 'sold': 801,\n",
       " 'bqhzwn': 802,\n",
       " 'easy': 803,\n",
       " 'international': 804,\n",
       " 'youtu': 805,\n",
       " 'select': 806,\n",
       " 'begin': 807,\n",
       " 'legal': 808,\n",
       " 'transform': 809,\n",
       " 'dtampa': 810,\n",
       " 'minutes': 811,\n",
       " 'august': 812,\n",
       " 'register': 813,\n",
       " 'hall': 814,\n",
       " 'mso': 815,\n",
       " 'player': 816,\n",
       " 'states': 817,\n",
       " 'ebird': 818,\n",
       " 'processing': 819,\n",
       " 'cccccc': 820,\n",
       " 'american': 821,\n",
       " \"didn't\": 822,\n",
       " 'digital': 823,\n",
       " 'progress': 824,\n",
       " 'playing': 825,\n",
       " 'something': 826,\n",
       " 'listed': 827,\n",
       " 'books': 828,\n",
       " 'five': 829,\n",
       " 'baby': 830,\n",
       " 'believe': 831,\n",
       " 'jjosephmorrison': 832,\n",
       " 'proxima': 833,\n",
       " 'session': 834,\n",
       " 'either': 835,\n",
       " 'judaica': 836,\n",
       " 'recently': 837,\n",
       " 'ccae': 838,\n",
       " 'issues': 839,\n",
       " 'internet': 840,\n",
       " 'hand': 841,\n",
       " 'submitted': 842,\n",
       " 'accept': 843,\n",
       " 'checks': 844,\n",
       " 'campus': 845,\n",
       " 'third': 846,\n",
       " 'cards': 847,\n",
       " 'grill': 848,\n",
       " 'false': 849,\n",
       " \"jdeal's\": 850,\n",
       " 'large': 851,\n",
       " 'print': 852,\n",
       " 'university': 853,\n",
       " 'between': 854,\n",
       " 'jdealny': 855,\n",
       " 'method': 856,\n",
       " 'relevant': 857,\n",
       " 'training': 858,\n",
       " 'whether': 859,\n",
       " 'alertsp': 860,\n",
       " 'adding': 861,\n",
       " 'fall': 862,\n",
       " 'outline': 863,\n",
       " 'instructions': 864,\n",
       " 'house': 865,\n",
       " 'global': 866,\n",
       " 'requests': 867,\n",
       " 'visa': 868,\n",
       " 'ewidth': 869,\n",
       " 'charge': 870,\n",
       " 'transactional': 871,\n",
       " 'learning': 872,\n",
       " 'abroad': 873,\n",
       " 'mark': 874,\n",
       " 'layout': 875,\n",
       " \"we're\": 876,\n",
       " 'object': 877,\n",
       " 'survey': 878,\n",
       " 'include': 879,\n",
       " 'valid': 880,\n",
       " 'spring': 881,\n",
       " 'bedford': 882,\n",
       " 'styl': 883,\n",
       " 'stay': 884,\n",
       " 'ensure': 885,\n",
       " 'manhattan': 886,\n",
       " 'djayjutt': 887,\n",
       " 'displaying': 888,\n",
       " 'shopping': 889,\n",
       " 'form': 890,\n",
       " 'websql': 891,\n",
       " 'advertising': 892,\n",
       " 'action': 893,\n",
       " 'however': 894,\n",
       " 'limited': 895,\n",
       " 'short': 896,\n",
       " 'gkeay': 897,\n",
       " 'working': 898,\n",
       " 'current': 899,\n",
       " 'equiv': 900,\n",
       " 'donor': 901,\n",
       " 'history': 902,\n",
       " 'tracking': 903,\n",
       " 'ahxq': 904,\n",
       " 'guide': 905,\n",
       " 'appointment': 906,\n",
       " 'exceeded': 907,\n",
       " 'party': 908,\n",
       " 'wines': 909,\n",
       " 'wait': 910,\n",
       " 'library': 911,\n",
       " '\\t\\t\\t\\t\\t\\t': 912,\n",
       " 'monthly': 913,\n",
       " 'making': 914,\n",
       " 'maybe': 915,\n",
       " 'doctype': 916,\n",
       " 'widt': 917,\n",
       " 'settings': 918,\n",
       " 'reason': 919,\n",
       " 'mailer': 920,\n",
       " 'black': 921,\n",
       " 'actual': 922,\n",
       " 'contentlibrary': 923,\n",
       " 'external': 924,\n",
       " 'programs': 925,\n",
       " 'latest': 926,\n",
       " 'marketplace': 927,\n",
       " 'banking': 928,\n",
       " 'tuition': 929,\n",
       " 'friend': 930,\n",
       " 'section': 931,\n",
       " 'earned': 932,\n",
       " 'shadow': 933,\n",
       " 'bwidth': 934,\n",
       " 'chasepc': 935,\n",
       " 'less': 936,\n",
       " 'kdqoncg': 937,\n",
       " 'jerusalem': 938,\n",
       " 'namecheap': 939,\n",
       " 'accounts': 940,\n",
       " \"week's\": 941,\n",
       " 'done': 942,\n",
       " 'needs': 943,\n",
       " 'themenlohouse': 944,\n",
       " 'else': 945,\n",
       " 'trip': 946,\n",
       " 'prod': 947,\n",
       " 'allow': 948,\n",
       " 'enrollment': 949,\n",
       " 'ever': 950,\n",
       " 'dede': 951,\n",
       " 'gets': 952,\n",
       " 'women': 953,\n",
       " 'copyright': 954,\n",
       " 'dgoods': 955,\n",
       " 'approved': 956,\n",
       " 'category': 957,\n",
       " 'sincerely': 958,\n",
       " 'fixed': 959,\n",
       " 'delicious': 960,\n",
       " 'columns': 961,\n",
       " 'namefont': 962,\n",
       " 'wanted': 963,\n",
       " 'tomorrow': 964,\n",
       " 'choose': 965,\n",
       " 'idth': 966,\n",
       " 'computer': 967,\n",
       " 'donate': 968,\n",
       " 'front': 969,\n",
       " 'exactly': 970,\n",
       " 'later': 971,\n",
       " 'advertisement': 972,\n",
       " 'twaqaaaaa': 973,\n",
       " 'clean': 974,\n",
       " 'tilt': 975,\n",
       " 'local': 976,\n",
       " 'four': 977,\n",
       " 'doing': 978,\n",
       " 'pocketfives': 979,\n",
       " 'nomob': 980,\n",
       " 'lock': 981,\n",
       " 'includes': 982,\n",
       " 'repl': 983,\n",
       " 'eight': 984,\n",
       " 'jacksonville': 985,\n",
       " 'create': 986,\n",
       " 'charset': 987,\n",
       " 'summary': 988,\n",
       " 'conditions': 989,\n",
       " 'externalclass': 990,\n",
       " 'talk': 991,\n",
       " 'saturday': 992,\n",
       " 'jeffrey': 993,\n",
       " 'dmerchandising': 994,\n",
       " 'wtsbb': 995,\n",
       " 'customers': 996,\n",
       " 'door': 997,\n",
       " 'thekill': 998,\n",
       " 'taking': 999,\n",
       " 'care': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "l7ImvnQAPopT",
    "outputId": "b1171f85-33fd-49c6-d8b1-dc4ba1f1fb5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10078, 15) (10078,)\n",
      "(1120, 15) (1120,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train/test prior to prepping for each model\n",
    "\n",
    "X = df.drop(columns=['tag_list', 'first_tag'])\n",
    "\n",
    "Y = df['first_tag']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.10, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Inv2Xxd5e9yH"
   },
   "source": [
    "#### Format all of the inputs for each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "fkUoeZlRPjCi",
    "outputId": "5537b812-44b2-44f9-a3ea-a8d203ce3f62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (10078, 5000)\n",
      "Shape of data tensor: (1120, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Format the inputs for Model 1 of predicting tag from message body\n",
    "\n",
    "Message_X_train = tokenizer.texts_to_sequences(X_train['Clean_Message'].values)\n",
    "Message_X_train = pad_sequences(Message_X_train, maxlen=5000)\n",
    "print('Shape of data tensor:', Message_X_train.shape)\n",
    "\n",
    "Message_X_test = tokenizer.texts_to_sequences(X_test['Clean_Message'].values)\n",
    "Message_X_test = pad_sequences(Message_X_test, maxlen=5000)\n",
    "print('Shape of data tensor:', Message_X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "TkHlIFgZT_w3",
    "outputId": "1324624c-505c-4bcb-ea10-e4f326104800"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (10078, 150)\n",
      "Shape of data tensor: (1120, 150)\n"
     ]
    }
   ],
   "source": [
    "# Format the inputs for Model 2 of predicting tag from message subject\n",
    "\n",
    "# First need to get length of subject messages\n",
    "\n",
    "clean_subject_length = df['Clean_Subject'].apply(len)\n",
    "(clean_subject_length < 150).value_counts()\n",
    "\n",
    "# Most are below 150 in length, will use this to pad\n",
    "\n",
    "Subject_X_train = tokenizer.texts_to_sequences(X_train['Clean_Subject'].values)\n",
    "Subject_X_train = pad_sequences(Subject_X_train, maxlen=150)\n",
    "print('Shape of data tensor:', Subject_X_train.shape)\n",
    "\n",
    "Subject_X_test = tokenizer.texts_to_sequences(X_test['Clean_Subject'].values)\n",
    "Subject_X_test = pad_sequences(Subject_X_test, maxlen=150)\n",
    "print('Shape of data tensor:', Subject_X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "Dpyf6fJYX9Kz",
    "outputId": "8b7427b2-fe29-4210-bb4b-1c0a0343a4f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.714770494731205\n",
      "Shape of data tensor: (10078, 100)\n",
      "Shape of data tensor: (1120, 100)\n"
     ]
    }
   ],
   "source": [
    "# Format the inputs for Model 3 of predicting tag from message sender\n",
    "\n",
    "# First need to get length of From messages sender\n",
    "\n",
    "clean_from_length = df['Clean_From'].apply(len)\n",
    "mean = clean_from_length.mean()\n",
    "print(mean)\n",
    "(clean_from_length < 100).value_counts()\n",
    "\n",
    "# Most are below 100 in length, will use this to pad\n",
    "\n",
    "From_X_train = tokenizer.texts_to_sequences(X_train['Clean_From'].values)\n",
    "From_X_train = pad_sequences(From_X_train, maxlen=100)\n",
    "print('Shape of data tensor:', From_X_train.shape)\n",
    "\n",
    "From_X_test = tokenizer.texts_to_sequences(X_test['Clean_From'].values)\n",
    "From_X_test = pad_sequences(From_X_test, maxlen=100)\n",
    "print('Shape of data tensor:', From_X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "MlNViWFYHHLA",
    "outputId": "de9b62f6-deac-4350-9107-a7f0990fe792"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (10078, 8)\n",
      "Shape of label tensor: (1120, 8)\n"
     ]
    }
   ],
   "source": [
    "# Format the Y inputs with encoding\n",
    "\n",
    "Encoded_Y_train = pd.get_dummies(Y_train).values\n",
    "print('Shape of label tensor:', Encoded_Y_train.shape)\n",
    "\n",
    "Encoded_Y_test = pd.get_dummies(Y_test).values\n",
    "print('Shape of label tensor:', Encoded_Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "oBpVjSd2PI0K",
    "outputId": "a797ac3d-9a51-4d88-b2c4-c1c41a84055c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Entertainment', 'Events', 'Finance', 'Other', 'Productivity',\n",
      "       'Shopping', 'Social', 'Travel'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Use these columns for the labels when decoding the neural net\n",
    "\n",
    "print(pd.get_dummies(df['first_tag']).columns)\n",
    "\n",
    "labels = ['Entertainment', 'Events', 'Finance', 'Other', 'Productivity',\n",
    "       'Shopping', 'Social', 'Travel']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mVfjt_nPE2qq"
   },
   "source": [
    "#### Setting up the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mm_tf0BvuDF-"
   },
   "outputs": [],
   "source": [
    "# LSTM function\n",
    "\n",
    "# 94.64 acc\n",
    "# Increased second layer GRU to 100 and all dropouts to 0.3\n",
    "# Also changed validation from test to validation split and increased epochs 3-5\n",
    "\n",
    "'''\n",
    "Combining both current running model tunings together\n",
    "Adding 1 GRU layer, Xupping GRU layers to 100 besides finalX too much, dropouts to 0.3, epochs to 5, validation_split, \n",
    "'''\n",
    "\n",
    "\n",
    "def create_lstm(X):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(50000, 100, input_length=X.shape[1]))\n",
    "    model.add(LSTM(100, dropout=0.5, recurrent_dropout=0.5, return_sequences=True))\n",
    "    model.add(GRU(100, dropout=0.5, recurrent_dropout=0.5, return_sequences=True))\n",
    "    model.add(GRU(50, dropout=0.5, recurrent_dropout=0.5, return_sequences=True))\n",
    "    model.add(GRU(50, dropout=0.5, recurrent_dropout=0.5))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Could still RE-Test with More Data if this model will be better or not with additional GRU layer & dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SWsOg6J35KQN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Model for message, subject, and sender\n",
    "\n",
    "message_model = create_lstm(Message_X_train)\n",
    "subject_model = create_lstm(Subject_X_train)\n",
    "from_model = create_lstm(From_X_train)\n",
    "\n",
    "# Combine them all for the activation input\n",
    "\n",
    "combined_input = concatenate([message_model.output, subject_model.output, from_model.output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 798
    },
    "colab_type": "code",
    "id": "M93mOgWzDzUr",
    "outputId": "8c8e8244-dc54-48e8-88f9-8e7676d5a6a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "embedding_input (InputLayer)    [(None, 5000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1_input (InputLayer)  [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2_input (InputLayer)  [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 5000, 100)    5000000     embedding_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 150, 100)     5000000     embedding_1_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 100, 100)     5000000     embedding_2_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 5000, 100)    80400       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 150, 100)     80400       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 100, 100)     80400       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "gru (GRU)                       (None, 5000, 100)    60300       lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "gru_3 (GRU)                     (None, 150, 100)     60300       lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru_6 (GRU)                     (None, 100, 100)     60300       lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, 5000, 50)     22650       gru[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "gru_4 (GRU)                     (None, 150, 50)      22650       gru_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru_7 (GRU)                     (None, 100, 50)      22650       gru_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     (None, 50)           15150       gru_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru_5 (GRU)                     (None, 50)           15150       gru_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru_8 (GRU)                     (None, 50)           15150       gru_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 150)          0           gru_2[0][0]                      \n",
      "                                                                 gru_5[0][0]                      \n",
      "                                                                 gru_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 8)            1208        concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 15,536,708\n",
      "Trainable params: 15,536,708\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# End activation of model\n",
    "\n",
    "x = Dense(8, activation='softmax')(combined_input)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.set_session\n",
    "\n",
    "model = Model(inputs=[message_model.input, subject_model.input, from_model.input], outputs=x)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "uu2MMQDCE97p",
    "outputId": "7099cc0e-9479-48c0-c15e-5ad3c76ae26d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model...\n",
      "Train on 9070 samples, validate on 1008 samples\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "batch_size=64\n",
    "\n",
    "history1 = model.fit(\n",
    "\t[Message_X_train, Subject_X_train, From_X_train], Encoded_Y_train,\n",
    "\tvalidation_split = 0.1,\n",
    "\tepochs=epochs, batch_size=batch_size,\n",
    "  callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)]\n",
    "  )\n",
    " \n",
    "# make predictions on the testing data\n",
    "print(\"[INFO] predicting labels...\")\n",
    "preds = model.predict([Message_X_test, Subject_X_test, From_X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CI0RbAIZHKTB"
   },
   "outputs": [],
   "source": [
    "## Side notes to look back into, especially attention layer\n",
    "\n",
    "# GRU layers can be added as well as LSTM, GRU > LSTM\n",
    "\n",
    "# attention models or attention transformed models\n",
    "\n",
    "# clustering in different forms for unsupervised training and then try to label them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NXxmsFaoCm6m"
   },
   "outputs": [],
   "source": [
    "# Saving model and weights\n",
    "\n",
    "#---------------------------\n",
    "## Change name each time ##\n",
    "#---------------------------\n",
    "\n",
    "\n",
    "from keras.models import model_from_json\n",
    "model_json = model.to_json()\n",
    "with open(\"combined_model_GRU.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"combined_weights_GRU.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OXGfCeNCMKcg"
   },
   "outputs": [],
   "source": [
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "996HRv8e-qfo",
    "outputId": "21fee373-d44e-41cc-ab71-b08810874c8b"
   },
   "outputs": [],
   "source": [
    "first = df['Clean_Message'][0]\n",
    "len(first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "colab_type": "code",
    "id": "rNZV1AJ5MQwi",
    "outputId": "ea35bf24-08ff-4a43-a4e0-0614d993bd2a"
   },
   "outputs": [],
   "source": [
    "# # load json and create model\n",
    "# json_file = open('test_model.json', 'r')\n",
    "# loaded_model_json = json_file.read()\n",
    "# json_file.close()\n",
    "# loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# # load weights into new model\n",
    "# loaded_model.load_weights(\"test_weights.h5\")\n",
    "# print(\"Loaded model from disk\")\n",
    "\n",
    "# def tag_email(text, model):\n",
    "#     '''\n",
    "#     Clean the text with the clean_text function\n",
    "\n",
    "#     Tokenize the text and pad it\n",
    "\n",
    "#     Use the loaded LSTM model softmax activation to predict the probability of each label\n",
    "#     for the email message being tested\n",
    "\n",
    "#     Return the highest argument as the predicted label\n",
    "#     '''\n",
    "\n",
    "#     text = clean_text(text)\n",
    "#     print('Text clean')\n",
    "#     print(text)\n",
    "#     print(len(text))\n",
    "#     seq = tokenizer.texts_to_sequences([text])\n",
    "#     print('Text sequenced')\n",
    "#     print(len(seq))\n",
    "#     padded = pad_sequences(seq, maxlen=5000)\n",
    "#     print('Text padded')\n",
    "#     print(len(padded))\n",
    "#     labels = ['Entertainment', 'Events', 'Finance', 'Other', 'Productivity', 'Shopping', 'Social', 'Travel']\n",
    "\n",
    "#     pred = model.predict(padded)\n",
    "#     print('Label predicted')\n",
    "#     return labels[np.argmax(pred)]\n",
    "# result = tag_email(first, loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7hSlOe38Iaxg",
    "outputId": "3b8f22eb-5b8a-4949-ffbf-4f44df83648d"
   },
   "outputs": [],
   "source": [
    "# result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4QNTbBnkKVow",
    "outputId": "6ab1b6ea-87c1-4c5d-d736-77a70219674a"
   },
   "outputs": [],
   "source": [
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JQBOKLxiHg8d"
   },
   "outputs": [],
   "source": [
    "accr = model.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_uEhz3oaYi6r"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "486-J91eYnjE"
   },
   "outputs": [],
   "source": [
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['acc'], label='train')\n",
    "plt.plot(history.history['val_acc'], label='test')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S7Nu6Ir1YrHQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Model_Test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
